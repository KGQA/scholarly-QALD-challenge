{
    "questions": [
        {
            "id": "AQ1600",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CIFAR-10 dataset in terms of Percentage correct metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage correct\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0009",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the AAN Corpus benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AAN Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1553",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the GENIA - LAS benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0675",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the ModelNet40 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ModelNet40\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0241",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Pitfall! dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Pitfall!\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1643",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of SOFT_SPL score when benchmarked on the Habitat 2020 Point Nav test-std dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SOFT_SPL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0876",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the ShARe/CLEF eHealth corpus benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ShARe/CLEF eHealth corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1972",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the modified TSE-NER model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"modified TSE-NER\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1990",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the TRE model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"TRE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1665",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Params metric on the CIFAR-10 Image Classification benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10 Image Classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0682",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the PROTEINS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PROTEINS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0969",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 James Bond dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0383",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the seel.cse.lsu.edu/data/re17.zip  dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"seel.cse.lsu.edu/data/re17.zip \")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0061",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the ChemProt dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ChemProt\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2215",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Bipartite flows (8 flows) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Bipartite flows (8 flows)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0208",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Dmlab-30 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0402",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ACE 2005 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACE 2005\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2255",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the NAT-M2 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NAT-M2\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1816",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the Birdsnap benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Birdsnap\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0309",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the PubMed 20k RCT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PubMed 20k RCT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1024",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the REDDIT-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"REDDIT-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1895",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Sentence Embeddings For Biomedical Texts research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Sentence Embeddings For Biomedical Texts\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2363",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CeiT-S (384 finetune resolution) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-S (384 finetune resolution)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0752",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the WLPC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WLPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0090",
            "query_type": "Non-factoid",
            "question": {
                "string": "What museums were involved in the IntARSI project?"
            },
            "paraphrased_question": [
                "What is the list of museums participated in the IntARSI project?"
            ],
            "query": {
                "sparql": "SELECT ?museums, ?museums_labels\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers rdfs:label ?papers_labels.\n  FILTER(REGEX(?papers_labels, \"IntARSI\"))\n  ?papers orkgp:P31 ?contrib.\n  ?contrib orkgp:P41242 ?museums.\n  ?museums rdfs:label ?museums_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0575",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the CL-SciSumm dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CL-SciSumm\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1838",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Question Answering research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Question Answering\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0055",
            "query_type": "Non-factoid/Count",
            "question": {
                "string": "What is the average energy generation for each energy source considered in 5 year intervals?"
            },
            "paraphrased_question": [
                "What are the mean values of energy generation for 5 years intervals grouped by energy source? "
            ],
            "query": {
                "sparql": "SELECT ?rangeId ?energy_sources_labels (AVG(?eng_gen_value) AS ?avg_eng_gen_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?paper orkgp:P31 ?contrib;\n         orkgp:P29 ?year.\n  BIND(xsd:int(?year) AS ?y).\n  VALUES (?rangeId ?min ?max) {\n    (\"2001-2005\" 2001 2005)\n    (\"2006-2010\" 2006 2010)\n    (\"2011-2015\" 2011 2015)\n    (\"2016-2020\" 2016 2020)\n  }\n  FILTER(?min <= ?y && ?y <= ?max).\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43134 ?energy_generation.\n  ?energy_generation orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?eng_gen_value).\n}\nORDER BY ASC(?rangeId)"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 7
        },
        {
            "id": "AQ2353",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BilBOWA model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BilBOWA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0785",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the HMDB51 (finetuned) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1019",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the EBM-NLP dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0448",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Hendrycks Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Hendrycks Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1390",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of NER Micro F1 score when benchmarked on the ACE 2004 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2004\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1650",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest spl score on the Gibson PointGoal Navigation benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"spl\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Gibson PointGoal Navigation\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0249",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Demon Attack dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Demon Attack\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0404",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the ChemProt dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ChemProt\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0222",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the MLDoc Zero-Shot English-to-Spanish dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Spanish\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1913",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Bi-RNN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Bi-RNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1684",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of ROUGE-2 score when benchmarked on the GigaWord dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-2\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GigaWord\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1735",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Error score when benchmarked on the TREC-6 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TREC-6\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1452",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the RACE dataset in terms of RACE-m metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RACE-m\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RACE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1766",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the Stanford Dogs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Stanford Dogs\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0398",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the JNLPBA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"JNLPBA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0387",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Pubmed dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Pubmed\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0780",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the STL-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STL-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1668",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of FLOPS metric on the DTD benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DTD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1938",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Pattern Matching and Learning model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Pattern Matching and Learning\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0996",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the SciCite benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1937",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Baseline tf-idf NPs model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Baseline tf-idf NPs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2339",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DQNMMCe model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQNMMCe\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0542",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Cheetah, run (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2390",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Neural Architecture Search model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Neural Architecture Search\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0878",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Ball in cup, catch (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1989",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the LUKE model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LUKE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1141",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the MultiRC dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiRC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0975",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Gravitar benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2106",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the ESIM + ELMo model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ESIM + ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2372",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the LeViT-128S model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LeViT-128S\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1354",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the STL-10, 1000 Labels dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10, 1000 Labels\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0129",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the One Billion Word dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"One Billion Word\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0277",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Bowling dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Bowling\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0938",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Asteroids dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asteroids\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0242",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Pong dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0291",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Amazon-2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Amazon-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0030",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the MAZEA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MAZEA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0077",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What is the most common type of biosensor?"
            },
            "paraphrased_question": [
                "What is the most frequently used biosensor type?"
            ],
            "query": {
                "sparql": "SELECT ?biosensor\nWHERE {\n  orkgr:R151435 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43095 ?biosensor.\n}\nORDER BY DESC(COUNT(?biosensor))\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ0943",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Alien benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Alien\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2269",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BioSentVec (MIMIC-III) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BioSentVec (MIMIC-III)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0087",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the WMT2016 Czech-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Czech-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1385",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CoNLL04 dataset in terms of NER Macro F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL04\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0263",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Time Pilot dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Time Pilot\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0921",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Name This Game dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Name This Game\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1016",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the BUCC Chinese-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC Chinese-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0496",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the WikiText-103 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-103\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1850",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Optical Character Recognition research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Optical Character Recognition\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2120",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Longformer (30 layers, h=512) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Longformer (30 layers, h=512)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1795",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Classic dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Classic\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1530",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Number of params score on the WikiText-103 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WikiText-103\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1635",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Cartpole, swingup (DMControl500k) dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1277",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Assault?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Assault\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0824",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Winograd Schema Challenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Winograd Schema Challenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2209",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Transformer-XL + RMS dynamic eval + decay model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL + RMS dynamic eval + decay\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0868",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the NCBI-disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NCBI-disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1734",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 Chopper Command dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Chopper Command\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2162",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the AWD-LSTM 3-layer with Fraternal dropout model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM 3-layer with Fraternal dropout\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1086",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset CoNLL04?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL04\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0677",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the PolyAI Reddit dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PolyAI Reddit\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2252",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the PopArt-IMPALA model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PopArt-IMPALA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1947",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the CRF layer with RNNs model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CRF layer with RNNs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0526",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the BC5CDR-chemical dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-chemical\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0516",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the AudioSet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AudioSet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2182",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Transformer-XL Standard model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL Standard\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0284",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 HERO dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 HERO\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1991",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Alt et al. (2019) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Alt et al. (2019)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0351",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Scholarly entity usage detection dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Scholarly entity usage detection\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0052",
            "query_type": "Non-factoid/Count/",
            "question": {
                "string": "What is the average installed capacity for each energy source considered?"
            },
            "paraphrased_question": [
                " What is the mean installed capacity for each energy source examined in the Greenhouse Gas Reduction Scenarios research?",
                " What is the average installed capacity for each energy source type in gigawatts?"
            ],
            "query": {
                "sparql": "SELECT ?energy_sources_labels (AVG(?installed_cap_value) AS ?average_installed_cap_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43133 ?installed_capacity.\n  ?installed_capacity orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?installed_cap_value)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0011",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "Which system has the worst recall?"
            },
            "paraphrased_question": [
                " Which system is the worst in terms of recall?",
                " Which system has the lowest recall score?",
                " Which system has the lowest sensitivity?"
            ],
            "query": {
                "sparql": "SELECT ?evaluation ?system_name\nWHERE {\n  orkgr:R6946 orkgp:compareContribution ?cont.\n  ?cont orkgp:P34 ?evaluation.\n  ?evaluation orkgp:P5015 ?recall;\n              rdfs:label ?system_name.\n  BIND(xsd:float(?recall) AS ?r)\n}\nORDER BY ?r\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0987",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the WOS-11967 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-11967\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0238",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Atari 2600 Double Dunk benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Double Dunk\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0981",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the TREC-6 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TREC-6\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1260",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset GigaWord?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GigaWord\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1487",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of EM metric on the SearchQA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SearchQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0459",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SQuAD1.1 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD1.1 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0080",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the 20NEWS benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"20NEWS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2002",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the multi-head + AT model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"multi-head + AT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1328",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Classic dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Classic\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0003",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the STEM-ECR v1.0 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STEM-ECR v1.0\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2173",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Sandwich Transformer model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sandwich Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2210",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the 24L Transformer + 8K adaptive span model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"24L Transformer + 8K adaptive span\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0662",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ObjectNet (Bounding Box) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ObjectNet (Bounding Box)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1532",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Validation perplexity score when benchmarked on the WikiText-103 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Validation perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WikiText-103\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2451",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the ELMO model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ELMO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0080",
            "query_type": "Non-factoid",
            "question": {
                "string": "Which energy system modeling papers indicate where to find their simulation software?"
            },
            "paraphrased_question": [
                "Which studies of energy systems do include links to corresponding models source code?"
            ],
            "query": {
                "sparql": "SELECT ?repo\nWHERE {\n  ?paper a orkgc:Paper.\n  ?paper orkgp:P31 ?contrib.\n  ?contrib orkgp:P37586 ?model.\n  ?model orkgp:P39010 ?code.\n  ?code orkgp:P4077 ?repo.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2425",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DY-ResNet-18 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-ResNet-18\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1223",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Reacher, easy (DMControl100k) dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0436",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Fashion-MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Fashion-MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2080",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the FusionNet (ensemble) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"FusionNet (ensemble)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0732",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the FB15k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FB15k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2051",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the AVID+CMA (Modified R2+1D-18 on Audioset) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVID+CMA (Modified R2+1D-18 on Audioset)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1079",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Amazon-5 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Amazon-5\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0014",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the SoMeSci dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SoMeSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1859",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Self-Supervised Action Recognition research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Self-Supervised Action Recognition\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0648",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Reuters De-En dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters De-En\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1781",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the Food-101 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Food-101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1203",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the DCASE dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DCASE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0100",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What is the maximum reaction yield for the studies? "
            },
            "paraphrased_question": [
                "What is the largest value of reaction yield obtained in the experiments?"
            ],
            "query": {
                "sparql": "SELECT ?reactions_yield WHERE {\n  orkgr:R137086 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37560 ?reactions_yield.\n}\nORDER BY DESC(?reactions_yield)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "HQ0070",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "For which region of data collection the number of sampling stations is the largest?"
            },
            "paraphrased_question": [
                "What studied location is characterized by the maximum number of sampling stations?"
            ],
            "query": {
                "sparql": "SELECT ?region\nWHERE {\n  orkgr:R155584 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P41068 ?number_of_stations;\n           orkgp:P27029 ?region.\n}\nORDER BY DESC(?number_of_stations)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1093",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SciERC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciERC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2200",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Inan et al. (2016) - Variational LSTM (tied) (h=650) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Inan et al. (2016) - Variational LSTM (tied) (h=650)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0470",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SQuAD2.0 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD2.0\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0048",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the IMDb dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2267",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BioSentVec (PubMed) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BioSentVec (PubMed)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1030",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SemEval-2018 Task 7 dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SemEval-2018 Task 7 dataset\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2168",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the R-Transformer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"R-Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1918",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Synthesizer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Synthesizer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2441",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BiLSTM-TDN model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-TDN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1564",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 score when benchmarked on the BC5CDR-chemical dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR-chemical\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1577",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of ROUGE-1 score when benchmarked on the X-Sum dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"X-Sum\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0261",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Venture dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2443",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the BiT-L (ResNet-152x4) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-L (ResNet-152x4)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1730",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Space Invaders benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Space Invaders\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0656",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Classical music, 5 seconds at 12 kHz dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Classical music, 5 seconds at 12 kHz\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0627",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 HERO dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 HERO\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0450",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Natural Questions (short) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions (short)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0193",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Walker, walk (DMControl100k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0373",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the MAZEA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MAZEA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2022",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the PBSMT + NMT model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT + NMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2088",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the BiDAF + Self Attention (single model) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiDAF + Self Attention (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0567",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-Chinese dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Chinese\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0899",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Food-101 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Food-101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1483",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of EM score when benchmarked on the SQuAD2.0 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD2.0 dev\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1636",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Cheetah, run (DMControl100k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2391",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the VGG11B(2x) + LocalLearning + CO model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VGG11B(2x) + LocalLearning + CO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1755",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Video Pinball dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Video Pinball\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2395",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the CeiT-S (384 finetune res) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-S (384 finetune res)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1077",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the IMDb dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2208",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Bipartite Flow model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Bipartite Flow\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2300",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Gorila model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Gorila\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1011",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the STL-10, 1000 Labels dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STL-10, 1000 Labels\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0095",
            "query_type": "Factoid/Temporal/",
            "question": {
                "string": "When MedPost model was published?"
            },
            "paraphrased_question": [
                "What is the year of the MedPost paper publication?"
            ],
            "query": {
                "sparql": "SELECT ?year\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers rdfs:label ?papers_labels.\n  FILTER(REGEX(?papers_labels, \"MedPost\"))\n  ?papers orkgp:P29 ?year.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "star",
            "query_class": "WHAT-WHEN",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1085",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset DuIE?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DuIE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0586",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Breakout dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1880",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Visual Navigation research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Visual Navigation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1621",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Params score when benchmarked on the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2045",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Video model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Video\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0871",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the CoNLL++ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL++\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1289",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Fishing Derby dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2324",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Reactor model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Reactor\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0865",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the MPQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MPQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0272",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Tutankham dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Tutankham\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1097",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the DDI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DDI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1644",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of SPL score when benchmarked on the Habitat 2020 Point Nav test-std dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SPL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1293",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Bank Heist?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Bank Heist\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0132",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the RotoWire (Content Ordering) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire (Content Ordering)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0939",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Kung-Fu Master benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Kung-Fu Master\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0230",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the arXiv benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"arXiv\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1329",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Recipe dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Recipe\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0900",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the CIFAR-10 Image Classification benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10 Image Classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2282",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Baseline : Lead-3 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Baseline : Lead-3\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1106",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the WMT2016 English-Czech dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-Czech\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1555",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the DCASE dataset in terms of Top-1 Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DCASE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1894",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Cross-Lingual Document Classification research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Cross-Lingual Document Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0670",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Sequential CIFAR-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Sequential CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1003",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Kuzushiji-MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2188",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the GCNN-14 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GCNN-14\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0701",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Softcite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Softcite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0293",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Yelp-2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1094",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset ADE Corpus?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0859",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the AudioSet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AudioSet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1456",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the DROP Test dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DROP Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1517",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Parameters score when benchmarked on the SNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Parameters\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0667",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Birdsnap dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Birdsnap\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1495",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of DLD score when benchmarked on the RotoWire (Content Ordering) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"DLD\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire (Content Ordering)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1858",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Video Classification research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Video Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0069",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "Which sector is the most commonly modeled energy sector?"
            },
            "paraphrased_question": [
                "Which energy sector is the most frequent for the studies?"
            ],
            "query": {
                "sparql": "SELECT ?label (COUNT(?label) AS ?number)\nWHERE {\n  ?sector rdfs:label ?label;\n          a ?class.\n  ?class owl:equivalentClass <http://openenergy-platform.org/ontology/oeo/OEO_00000367>.\n  orkgr:R150337 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37586 ?scenario.\n  ?scenario orkgp:P37675 ?study.\n  ?study orkgp:P37668 ?sector.\n  \n}\nORDER BY DESC(?number)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "cycle",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 7
        },
        {
            "id": "HQ0063",
            "query_type": "Factoid",
            "question": {
                "string": "Is Cobb-Douglas functional applied in the studies?"
            },
            "paraphrased_question": [
                "Is CobbDouglas production function being used for the studies?"
            ],
            "query": {
                "sparql": "ASK {\n  orkgr:R34493 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15661 ?funcionals.\n  ?funcionals rdfs:label ?funtionals_labels.\n  FILTER(REGEX(?funtionals_labels, \"Cobb-Douglas\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0414",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the CIFAR-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0954",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Asterix dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0327",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Sequential CIFAR-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Sequential CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1186",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Penn Treebank (Character Level) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank (Character Level)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0934",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Assault dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Assault\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0188",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the NCBI Disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NCBI Disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0285",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Atari 2600 Q*Bert benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Q*Bert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0788",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Reuters-21578 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters-21578\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2365",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CeiT-S model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-S\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1482",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the SQuAD2.0 dev benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD2.0 dev\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1201",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the GENIA - LAS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2262",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Massively Multilingual Sentence Embeddings model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Massively Multilingual Sentence Embeddings\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0323",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the ObjectNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ObjectNet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1551",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the MRPC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MRPC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0512",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the SentEval dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SentEval\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2197",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the AWD-LSTM + ATOI model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM + ATOI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1882",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Coreference Resolution research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Coreference Resolution\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0178",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Yelp Fine-grained classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp Fine-grained classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1084",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset JNLPBA?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"JNLPBA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0008",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What is the least common metric used?"
            },
            "paraphrased_question": [
                "What metric is the least frequently used in studies?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?name\nWHERE {\n ?paper a orkgc:Paper;\n orkgp:P31 [\n   orkgp:P5003 [\n     rdfs:label ?name\n   ]\n ].\n {\n   SELECT DISTINCT (COUNT(?paper_) AS ?min_papers)\n   WHERE {\n    ?paper_ a orkgc:Paper;\n    orkgp:P31 [\n      orkgp:P5003 [\n      rdfs:label ?name_\n      ]\n    ].\n  }\n  GROUP BY ?name_\n  ORDER BY ?min_papers\n  LIMIT 1\n }\n}\nGROUP BY ?name ?min_papers\nHAVING(COUNT(?paper) = ?min_papers)\nORDER BY ?name"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "forest",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 8
        },
        {
            "id": "AQ1409",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the WLPC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WLPC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1471",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the COPA dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"COPA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0397",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the NYT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1557",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Top-1 Accuracy metric on the ESC-50 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ESC-50\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0380",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the smallNLP-KG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"smallNLP-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0419",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2014 French-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1379",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the TACRED benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TACRED\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0882",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Reacher, easy (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0637",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Yelp-5 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-5\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1139",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Natural Questions?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Natural Questions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1394",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of RE+ Micro F1 metric on the ACE 2005 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE+ Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1732",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 HERO dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 HERO\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0654",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0027",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the SciGEN dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciGEN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1140",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset BioASQ?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BioASQ\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2414",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the CvT-13 (384 res) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-13 (384 res)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1840",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Named Entity Recognition research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Named Entity Recognition\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0903",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Reuters RCV1/RCV2 English-to-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1719",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Wizard of Wor dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Wizard of Wor\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2233",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the L3 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"L3\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0815",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the One Billion Word dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"One Billion Word\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2299",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DDQN+Pop-Art noop model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDQN+Pop-Art noop\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0109",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the PubMedQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PubMedQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0001",
            "query_type": "Factoid",
            "question": {
                "string": "What type of data does the system proposed in paper titled \"Open Research Knowledge Graph\" support?"
            },
            "paraphrased_question": [
                "What kind of data does the system in \"paper title\" paper support?"
            ],
            "query": {
                "sparql": "SELECT ?datatype \nWHERE {\n  orkgr:R8364 orkgp:compareContribution ?cont.\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?title.\n  ?cont  orkgp:P7046 ?sys.\n  ?sys orkgp:P7055 ?datatype.\n  FILTER(REGEX(STR(?title), \"Open Research Knowledge Graph\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "forest",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2070",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the OTF dict+spelling (single) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"OTF dict+spelling (single)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0953",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Wizard of Wor benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Wizard of Wor\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0896",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the FGVC Aircraft benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0384",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the FSNS - Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FSNS - Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0123",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the CNN / Daily Mail dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CNN / Daily Mail\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0131",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the RotoWire (Relation Generation) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire (Relation Generation)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1729",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Boxing benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Boxing\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2419",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CvT-13 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-13\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0357",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SoMeSci dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SoMeSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2234",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Triplet model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Triplet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0420",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2016 English-Czech dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Czech\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0572",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the X-Sum dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"X-Sum\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0915",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the X-Sum dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"X-Sum\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1004",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the ImageNet ReaL dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet ReaL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1127",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the UCF101 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0103",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the RACE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RACE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0457",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the BoolQ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BoolQ\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        }
    ]
}