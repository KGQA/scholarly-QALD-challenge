{
    "questions": [
        {
            "id": "AQ0508",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the DDI extraction 2013 corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI extraction 2013 corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2344",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the A2C+CoEX model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"A2C+CoEX\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2349",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Orthogonalized Soft VSM model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Orthogonalized Soft VSM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0169",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the SentEval dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SentEval\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0119",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the COPA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"COPA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0179",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the MPQA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MPQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1912",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Memory Compressed model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Memory Compressed\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1857",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Image Generation research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Image Generation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1751",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Defender dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Defender\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1222",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Walker, walk (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0891",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Habitat 2020 Point Nav test-std benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1488",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Number of params score when benchmarked on the One Billion Word dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"One Billion Word\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1090",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the ChemProt dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0004",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the AI-KG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AI-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1861",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Multi-Task Learning research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Multi-Task Learning\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0332",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the ModelNet40 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ModelNet40\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2375",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the VGG8B + LocalLearning + CO model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VGG8B + LocalLearning + CO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1509",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Matched score on the MultiNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Matched\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1837",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Information Extraction research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Information Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0160",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the BIOSSES dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BIOSSES\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0010",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the TSE-NER dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TSE-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0268",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Asterix dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1294",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Kangaroo dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Kangaroo\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2007",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Ours: cross-sentence ALB model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Ours: cross-sentence ALB\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0965",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Road Runner dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Road Runner\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0040",
            "query_type": "Factoid",
            "question": {
                "string": "Which countries are considered in the papers about geopolitics?"
            },
            "paraphrased_question": [
                "About which countries are there research papers on geopolitcs?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?location\nWHERE {\n  ?_ orkgp:compareContribution [\n    orkgp:P32 [\n      rdfs:label ?label\n    ];\n    orkgp:P5049 ?location\n  ]\n  FILTER(REGEX(STR(?label), \"geopoli?tics\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHAT-WHEN",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2448",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the ViT-B/16 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ViT-B/16\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1893",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the relation extraction research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"relation extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0057",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the CoNLL04 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL04\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1318",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Gravitar dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1459",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Natural Questions dataset in terms of F1 (Long) metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 (Long)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Natural Questions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1271",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Pong dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0367",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Dataset mentions in Social Sciences dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dataset mentions in Social Sciences\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1693",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Double Dunk benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Double Dunk\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0982",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Ohsumed benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ohsumed\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0801",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the CommonsenseQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1190",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0738",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the TACRED dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TACRED\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1875",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Sentiment Analysis research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Sentiment Analysis\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0184",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the BC2GM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1834",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Automated Reinforcement Learning (AutoRL) research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Automated Reinforcement Learning (AutoRL)\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1053",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Dataset mentions in Social Sciences?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Dataset mentions in Social Sciences\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2043",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Image Transformer model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Image Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1682",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of ROUGE-L metric on the GigaWord benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-L\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GigaWord\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1796",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the Recipe dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Recipe\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2303",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DARQN soft model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DARQN soft\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0556",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Food-101 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Food-101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2244",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Linear SVM model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linear SVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0477",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ARC (Challenge) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Challenge)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0621",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Battle Zone dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Battle Zone\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1446",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the HMDB51 dataset in terms of Top-1 Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0832",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the SNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1814",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Top 5 Accuracy score on the ObjectNet benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 5 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1749",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Pitfall! benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pitfall!\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0770",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the IWSLT2015 German-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0772",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the WMT2016 Russian-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Russian-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1963",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the LibLinear model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LibLinear\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0183",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the BC5CDR-chemical dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-chemical\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0783",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Multimodal PISA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Multimodal PISA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2381",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the EffNet-L2 (SAM) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EffNet-L2 (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1959",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the EneRex model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EneRex\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2053",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the AVID+CMA (Modified R2+1D-18 on Kinetics) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVID+CMA (Modified R2+1D-18 on Kinetics)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2312",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DQN Best model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN Best\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2144",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the 12-layer Character Transformer Model model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"12-layer Character Transformer Model\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1123",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the STL-10 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0212",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the CINIC-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1700",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Berzerk benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Berzerk\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0229",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the X-Sum dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"X-Sum\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1343",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the VTAB-1k dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"VTAB-1k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1565",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 entity level score when benchmarked on the BC5CDR-chemical dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 entity level\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR-chemical\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2184",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Rfa-Gate-Gaussian-Stateful (Small) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Rfa-Gate-Gaussian-Stateful (Small)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1927",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Luna model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Luna\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1533",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Bits per byte score on the The Pile benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bits per byte\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"The Pile\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0375",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Annotated development corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Annotated development corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0950",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Bank Heist benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Bank Heist\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0051",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the WebNLG benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0013",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What was the most common type of approach for summarization before 2002?"
            },
            "paraphrased_question": [
                "Which was the most popular approach for summarization until 2002?"
            ],
            "query": {
                "sparql": "SELECT ?approach ?approach_label\nWHERE {\n  orkgr:R6948 orkgp:compareContribution ?cont.\n  ?cont orkgp:P15 ?implementation.\n  ?implementation orkgp:P5043 ?approach.\n  ?approach rdfs:label ?approach_label.\n}\nORDER BY DESC(COUNT(?approach_label))\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1443",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Pre-Training Dataset score on the UCF101 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Pre-Training Dataset\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0744",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ACE 2004 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACE 2004\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2085",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the FusionNet (single model) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"FusionNet (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0273",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Tennis dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Tennis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0061",
            "query_type": "Non-factoid",
            "question": {
                "string": "Which vegetables are utilized for betanin extraction?"
            },
            "paraphrased_question": [
                "What vegetables are used in the process of betanin extraction?"
            ],
            "query": {
                "sparql": "SELECT ?vegetables, ?vegetables_labels\nWHERE {\n  orkgr:R75363 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P35147 ?compounds.\n  ?compounds rdfs:label ?compounds_labels.\n  FILTER(REGEX(?compounds_labels, \"etanin\"))\n  ?contrib orkgp:P35148 ?vegetables.\n  ?vegetables rdfs:label ?vegetables_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1619",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Top 1 Accuracy score when benchmarked on the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0724",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Car speed in Liuliqiao District, Beijing dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Car speed in Liuliqiao District, Beijing\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0086",
            "query_type": "Non-factoid",
            "question": {
                "string": "What are the research problems Vernier Effect is related to?"
            },
            "paraphrased_question": [
                "What is the list of research problems related to Vernier effect?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?problems, ?problems_labels\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers rdfs:label ?papers_labels.\n  FILTER(REGEX(?papers_labels, \"Vernier Effect\", \"i\"))\n  ?papers orkgp:P31 ?contrib.\n  ?contrib orkgp:P32 ?problems.\n  ?problems rdfs:label ?problems_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2460",
            "query_type": "Factoid",
            "question": {
                "string": "Are there any research problems with benchmark datasets in the realm of Natural Language Processing research?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?problem ?problem_lbl\nWHERE {\n  ?rf       a            orkgc:ResearchField;\n            rdfs:label   ?rf_label.\n  FILTER (str(?rf_label) = \"Natural Language Processing\")\n  ?paper    orkgp:P30    ?rf;\n            orkgp:P31    ?cont.\n  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                orkgp:P32                ?problem.\n  ?problem      rdfs:label               ?problem_lbl.\n}"
            },
            "template_id": "T08",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0008",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Scholarly entity usage detection dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Scholarly entity usage detection\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0418",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2014 English-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1987",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the ETL-Span model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ETL-Span\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0252",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Asteroids dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asteroids\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0037",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the smallNLP-KG benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"smallNLP-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0302",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the HoC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HoC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0803",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the WebQuestions dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebQuestions\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0062",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the SemEval-2010 Task 8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0870",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the BC2GM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0401",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the ACE 2004 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACE 2004\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0465",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the SQuAD1.1 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD1.1\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1973",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SciBERT + CNN model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT + CNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1057",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset CS-NER?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CS-NER\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0001",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the SemEval-2018 Task 7 dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2018 Task 7 dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1279",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 River Raid?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 River Raid\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0099",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the HMDB51 (finetuned) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1523",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the LAMBADA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"LAMBADA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0986",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Recipe dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Recipe\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2369",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the LeViT-256 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LeViT-256\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0092",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the ImageNet 64x64 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet 64x64\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1292",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Time Pilot dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Time Pilot\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1652",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy (%) score when benchmarked on the FGVC Aircraft dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2239",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BiLSTM-CRF+ELMo model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-CRF+ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0502",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the MedSTS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedSTS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2373",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the CAIT-M36-448 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-M36-448\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0308",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Paper Field dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Paper Field\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0194",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Reacher, easy (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1205",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the UrbanSound8k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UrbanSound8k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0723",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the smallNLP-KG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"smallNLP-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1400",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the ChemProt dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0826",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Words in Context dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Words in Context\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1750",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Skiing benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Skiing\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1159",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Rotowire (Content Selection) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Rotowire (Content Selection)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1595",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest ROUGE-1 score on the Pubmed benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Pubmed\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0974",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Star Gunner dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Star Gunner\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1253",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the MLDoc Zero-Shot English-to-Chinese dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Chinese\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0018",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the SciERC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0035",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the DRI Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DRI Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2258",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Biinclusion (Euro500kReuters) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Biinclusion (Euro500kReuters)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0985",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Classic dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Classic\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0120",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the TriviaQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TriviaQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2135",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer-XL + RMS dynamic eval model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL + RMS dynamic eval\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1908",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the LNN-EL/ens model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LNN-EL/ens\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1609",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy (%) metric on the STL-10 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2113",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SRU++ Large model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SRU++ Large\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0276",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Private Eye dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2306",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DQN hs model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0776",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Stanford Dogs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Stanford Dogs\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1048",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the SemEval-2021 Task 11 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SemEval-2021 Task 11\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0483",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Words in Context dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Words in Context\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0011",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the ORKG-TDM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0075",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the WMT2014 English-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2175",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer-XL Large model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL Large\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1933",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Stable and Transferable Mixture-of-Experts model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Stable and Transferable Mixture-of-Experts\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0519",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the UrbanSound8k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UrbanSound8k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2420",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CAIT-XXS-24 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-XXS-24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1324",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset TREC-6?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TREC-6\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1091",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the SemEval-2010 Task 8 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2399",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the EfficientNet-L2-475 (SAM) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EfficientNet-L2-475 (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1983",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Transformer model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0998",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the ScienceCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ScienceCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0690",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the AI-KG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AI-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2283",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Baseline : Random model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Baseline : Random\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2438",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the VGG11B(3x) + LocalLearning model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VGG11B(3x) + LocalLearning\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2302",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Recurrent Rational DQN Average model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Recurrent Rational DQN Average\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0225",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the MLDoc Zero-Shot English-to-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1818",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Macro F1 score when benchmarked on the PWC Leaderboards (restricted) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0403",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the GAD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2179",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the PAR Transformer Base model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PAR Transformer Base\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0237",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Crazy Climber dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Crazy Climber\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0691",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the SciREX dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciREX\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0413",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AG News dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AG News\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0423",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the 20NEWS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"20NEWS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1862",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Text Generation research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Text Generation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0307",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Reuters En-De dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters En-De\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1521",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the enwik8 dataset in terms of Number of params metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwik8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0218",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Reuters RCV1/RCV2 German-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 German-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1489",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the One Billion Word dataset in terms of PPL metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PPL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"One Billion Word\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0140",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Words in Context dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Words in Context\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0642",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Classic dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Classic\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1896",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Graph Embedding research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Graph Embedding\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1238",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the ClueWeb09-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ClueWeb09-B\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0838",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Penn Treebank (Word Level) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1515",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the MedNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MedNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2062",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the BERT-joint model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BERT-joint\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1952",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BERT classifier model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BERT classifier\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0363",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ner_dataset_recognition dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ner_dataset_recognition\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0766",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the 20NEWS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"20NEWS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0704",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the SciERC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1653",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of FLOPS score when benchmarked on the FGVC Aircraft dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1800",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the Reuters De-En benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters De-En\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2178",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Feedback Transformer (4 layers) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Feedback Transformer (4 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1618",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2240",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the NCBI_BERT(base) (P) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NCBI_BERT(base) (P)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1849",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the stochastic classification research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"stochastic classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0300",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Recipe dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Recipe\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2335",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Intrinsic Reward Agent model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Intrinsic Reward Agent\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1392",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of RE Micro F1 metric on the ACE 2004 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2004\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1193",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset TempEval-3?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TempEval-3\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0223",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the MLDoc Zero-Shot English-to-Russian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Russian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0569",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the MLDoc Zero-Shot English-to-Italian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1366",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the MUTAG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MUTAG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1312",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 James Bond?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2074",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BigBird model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BigBird\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1042",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset CommonsenseQA?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0940",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Krull dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1035",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset ARC-PDN?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ARC-PDN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0805",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the COPA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"COPA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2049",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the AVTS model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2089",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Dynamic Coattention Networks (ensemble) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Dynamic Coattention Networks (ensemble)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2310",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the DDRL A3C model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDRL A3C\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1817",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the STL-10, 1000 Labels dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10, 1000 Labels\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1579",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the X-Sum dataset in terms of ROUGE-3 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-3\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"X-Sum\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0730",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Pubmed benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Pubmed\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0049",
            "query_type": "Non-Factoid/Count",
            "question": {
                "string": "What is the average energy generation of all energy sources considered?"
            },
            "paraphrased_question": [
                "What is the mean value of energy generation for all energy sources in the studies?"
            ],
            "query": {
                "sparql": "SELECT (AVG(?elec_gen_value) AS ?average_elec_gen_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43134 ?electricity_generation.\n  FILTER(REGEX(?energy_sources_labels, \"all sources\"))\n  ?electricity_generation orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?elec_gen_value)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1464",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the BoolQ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BoolQ\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0456",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the CoQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1074",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Amazon dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Amazon\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1660",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest PARAMS score on the CINIC-10 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CINIC-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0774",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the WMT2016 Romanian-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Romanian-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2350",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the ApproxRepSet model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ApproxRepSet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1115",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the WMT2016 Russian-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 Russian-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0504",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2211",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer-XL - 24 layers model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL - 24 layers\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1137",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the DROP Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DROP Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1847",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Phrase Extraction research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Phrase Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0480",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the ARC (Easy) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2057",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Cluster-Former (#C=512) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Cluster-Former (#C=512)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1351",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the iNaturalist 2018 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"iNaturalist 2018\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0201",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Ball in cup, catch (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0819",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the RotoWire dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0841",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the WikiText-2 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1096",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the NYT24 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT24\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0600",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Alien dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Alien\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2143",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the mLSTM + dynamic eval model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"mLSTM + dynamic eval\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1375",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the Penn Treebank benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0346",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the STEM-ECR v1.0 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STEM-ECR v1.0\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1174",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the MedNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MedNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0467",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the QuAC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"QuAC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1965",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the entity and relations table model model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"entity and relations table model\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1778",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the FGVC Aircraft dataset in terms of Top-1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1627",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the MPQA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MPQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0857",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the GENIA - UAS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - UAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2035",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Transformer Big + adversarial MLE model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer Big + adversarial MLE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0388",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Amazon dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Amazon\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1322",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Yelp-2 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2341",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Sarsa-\u03c6-EB model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sarsa-\u03c6-EB\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0935",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Demon Attack benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Demon Attack\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1888",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Humor Detection research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Humor Detection\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0994",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Paper Field dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Paper Field\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1773",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the Reuters-21578 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters-21578\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1305",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Private Eye dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1842",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Named entity recognition research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Named entity recognition\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1342",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Classical music, 5 seconds at 12 kHz dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Classical music, 5 seconds at 12 kHz\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0335",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the PWC Leaderboards (restricted) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0845",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the MedSTS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedSTS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0355",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the TDM Tagged Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TDM Tagged Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1268",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari-57 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari-57\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2014",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the SpERT (without overlap) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpERT (without overlap)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2038",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SMT as posterior regularization model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SMT as posterior regularization\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0399",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the DuIE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DuIE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0216",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the AAPD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AAPD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2067",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the MPCM model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MPCM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1820",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Macro Precision score on the PWC Leaderboards (restricted) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1932",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the ST-MoE model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ST-MoE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0703",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the OA-STM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1065",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset NLP-TDMS?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1611",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest PARAMS score on the STL-10 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1493",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the RotoWire (Relation Generation) dataset in terms of count metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"count\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire (Relation Generation)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1064",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the DRI Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DRI Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2266",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the e2e-coref + ELMo model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"e2e-coref + ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1149",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the TriviaQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TriviaQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1175",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the SNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1863",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Data-to-Text Generation research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Data-to-Text Generation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1460",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 (Short) metric on the Natural Questions benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 (Short)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Natural Questions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0071",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the CIFAR-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0685",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Open Entity dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Open Entity\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1604",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest PARAMS score on the CIFAR-100 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1508",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the RTE dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RTE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0733",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Twitter dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Twitter\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1257",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Barabasi-Albert dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1845",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Scientific Claim Verification research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Scientific Claim Verification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1072",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the nuScenes dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"nuScenes\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0438",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Oxford 102 Flowers dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1510",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the CommitmentBank dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CommitmentBank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1067",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Car speed in Liuliqiao District, Beijing dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Car speed in Liuliqiao District, Beijing\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1711",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Alien benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Alien\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1680",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Entropy Difference score on the Barabasi-Albert benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Entropy Difference\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1173",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset ANLI test?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ANLI test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0576",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the AESLC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2322",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the LASER model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LASER\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0144",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the ANLI test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ANLI test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2225",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the He et al., 2017 + ELMo model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"He et al., 2017 + ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0674",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the BUCC Russian-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC Russian-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1118",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the IWSLT2015 English-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2409",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the EfficientNetV2-S (21k) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EfficientNetV2-S (21k)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1715",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 Time Pilot dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Time Pilot\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1269",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Ms. Pacman dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Ms. Pacman\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0100",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the UCF101 (finetuned) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1145",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SQuAD1.1 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD1.1 dev\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1395",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the ACE 2005 dataset in terms of RE Micro F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1046",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset OA-STM?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"OA-STM\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0956",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Yars Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Yars Revenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0608",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Kangaroo dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Kangaroo\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2464",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list benchmarked problems in the area of Information Science?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?problem ?problem_lbl\nWHERE {\n  ?rf       a            orkgc:ResearchField;\n            rdfs:label   ?rf_label.\n  FILTER (str(?rf_label) = \"Information Science\")\n  ?paper    orkgp:P30    ?rf;\n            orkgp:P31    ?cont.\n  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                orkgp:P32                ?problem.\n  ?problem      rdfs:label               ?problem_lbl.\n}"
            },
            "template_id": "T08",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0535",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Ball in cup, catch (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1552",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the GENIA - UAS benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GENIA - UAS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1958",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the word BiLSTM + char CNN + CRF model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"word BiLSTM + char CNN + CRF\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1974",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SciKG model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciKG\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0005",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the SciREX dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciREX\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0275",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Frostbite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2332",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DARQN hard model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DARQN hard\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1499",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the OpenBookQA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"OpenBookQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1696",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Pong dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1602",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CIFAR-10 dataset in terms of Search Time (GPU days) metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Search Time (GPU days)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0880",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Reacher, easy (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0025",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the SciFACT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2015",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SpERT (with overlap) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpERT (with overlap)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0669",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Sequential MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Sequential MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0111",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the BioASQ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BioASQ\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1529",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Validation perplexity score when benchmarked on the Penn Treebank (Word Level) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Validation perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1410",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the NYT24 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT24\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2231",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Perceiver model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Perceiver\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1397",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Relation F1 score on the ACE 2005 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Relation F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0047",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Twitter dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Twitter\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0012",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the TDM Tagged Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TDM Tagged Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1512",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of A1 metric on the ANLI test benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"A1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ANLI test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1543",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the DDI extraction 2013 corpus dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DDI extraction 2013 corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2432",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the ZFNet (ensemble, 6 convnets) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ZFNet (ensemble, 6 convnets)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1726",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Bowling dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Bowling\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0497",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the The Pile dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"The Pile\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1836",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Knowledge Graph Construction research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Knowledge Graph Construction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0983",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the BBCSport benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BBCSport\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0098",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the UCF101 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0584",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Pitfall! dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Pitfall!\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0534",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Finger, spin (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2386",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the EfficientNetV2-M model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EfficientNetV2-M\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2444",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BiT-M (ResNet-152x4) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-M (ResNet-152x4)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0002",
            "query_type": "Factoid",
            "question": {
                "string": "What is the scope of \"Decentralised Authoring, Annotations and Notifications for a Read-Write Web with Dokieli\"?"
            },
            "paraphrased_question": [
                "What type of scope does \"paper title\" consider?"
            ],
            "query": {
                "sparql": "SELECT ?scope \nWHERE {\n  orkgr:R8364 orkgp:compareContribution ?cont.\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?title.\n  ?cont orkgp:P7046 ?sys.\n  ?sys orkgp:P7047 ?scope.\n  FILTER(REGEX(STR(?title), \"Decentralised Authoring, Annotations and Notifications for a Read-Write Web with dokieli\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1556",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of PRE-TRAINING DATASET metric on the DCASE benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PRE-TRAINING DATASET\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DCASE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1497",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the ARC (Challenge) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ARC (Challenge)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0789",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the RACE benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RACE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1321",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the DBpedia dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DBpedia\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1713",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Fishing Derby benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0050",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Amazon-5 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Amazon-5\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0073",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the 200k Short Texts for Humor Detection benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"200k Short Texts for Humor Detection\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0127",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the SQuAD2.0 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD2.0\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0072",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What is the most common drug in the studies?"
            },
            "paraphrased_question": [
                "What drug is the most frequently appeared in the contributions?"
            ],
            "query": {
                "sparql": "SELECT ?drug, ?drug_labels\nWHERE {\n  orkgr:R155621 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37578 ?drug.\n  ?drug rdfs:label ?drug_labels.\n}\nORDER BY DESC(COUNT(?drug))\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0622",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Road Runner dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Road Runner\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0616",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Tennis dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Tennis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2044",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Sparse Transformer 152M (strided) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sparse Transformer 152M (strided)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2196",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the  GCNN-14 bottleneck model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \" GCNN-14 bottleneck\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1768",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the Fashion-MNIST benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Fashion-MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2378",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the ProjectionNet model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ProjectionNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0288",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Star Gunner dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Star Gunner\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0264",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Bank Heist dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Bank Heist\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2097",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the FusionNet++ (ensemble) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"FusionNet++ (ensemble)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1922",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Linear Transformer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linear Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1349",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset SVHN?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SVHN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2265",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BiLSTM (UN) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM (UN)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0790",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the CUB-200-2011 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CUB-200-2011\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0161",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2199",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Inan et al. (2016) - Variational LSTM (tied) (h=650) + augmented loss\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0916",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the arXiv dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"arXiv\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1121",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the ImageNet 64x64 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet 64x64\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0105",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Hendrycks Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Hendrycks Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1252",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the MLDoc Zero-Shot English-to-Russian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Russian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0505",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Cornell Grasp Dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cornell Grasp Dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2256",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the NAT-M1 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NAT-M1\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1194",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the DDI extraction 2013 corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DDI extraction 2013 corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0487",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ANLI test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ANLI test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1191",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Cornell Grasp Dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cornell Grasp Dataset\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0353",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the TSE-NER dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TSE-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0574",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the GigaWord dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GigaWord\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1901",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Text Classification research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Text Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0153",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WikiText-103 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-103\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2405",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CAIT-S-36 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-S-36\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2403",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the EfficientNetV2-M (21k) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EfficientNetV2-M (21k)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2127",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer-XL (12 layers) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL (12 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0731",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Amazon benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Amazon\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1597",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy (10 classes) score on the IMDb benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (10 classes)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0854",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the STS Benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STS Benchmark\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0615",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Tutankham dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Tutankham\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1550",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the SentEval dataset in terms of STS metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"STS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0602",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Solaris dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1607",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of FLOPS score when benchmarked on the Stanford Cars dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Stanford Cars\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1340",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0431",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the WMT2016 Romanian-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Romanian-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1283",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Krull dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0214",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the CIFAR-10 Image Classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10 Image Classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2367",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the LeViT-384 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LeViT-384\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1066",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset smallNLP-KG?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"smallNLP-KG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0334",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the PolyAI Reddit dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PolyAI Reddit\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0136",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the OpenBookQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OpenBookQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1114",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset WMT2016 English-German?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2392",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the SWWAE model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SWWAE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0024",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Dataset mentions in Social Sciences dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dataset mentions in Social Sciences\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1930",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Adaptively Sparse Transformer model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Adaptively Sparse Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2297",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DDQN (tuned) noop model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDQN (tuned) noop\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1794",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the IMDb-M dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb-M\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2247",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the OccupancyAnticipation model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"OccupancyAnticipation\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2356",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BiT-L (50 hypers/task) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-L (50 hypers/task)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0310",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the SciCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2213",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the 12L Transformer + 8K adaptive span model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"12L Transformer + 8K adaptive span\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0320",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the SVHN dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1426",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of BLEU score metric on the WMT2014 German-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0646",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WOS-5736 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2285",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the JointParsing model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"JointParsing\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2263",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the XLMft UDA model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLMft UDA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0093",
            "query_type": "Non-factoid",
            "question": {
                "string": "What are the research problems of the cultural history field?"
            },
            "paraphrased_question": [
                "What are the research challenges in the domain of Cultural History?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?research_problems, ?research_problems_labels\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers orkgp:P30 ?research_fields.\n  ?research_fields rdfs:label ?research_fields_labels. \n  FILTER(REGEX(?research_fields_labels, \"cultural history\", \"i\"))\n  ?papers orkgp:P31 ?contrib.\n  ?contrib orkgp:P32 ?research_problems.\n  ?research_problems rdfs:label ?research_problems_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1418",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of BLEU score score when benchmarked on the WMT2014 English-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1538",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Bit per Character (BPC) score on the Penn Treebank (Character Level) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bit per Character (BPC)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank (Character Level)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1821",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Macro Recall metric on the PWC Leaderboards (restricted) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro Recall\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2439",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the WRN28-10 (SAM) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"WRN28-10 (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1348",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the ObjectNet (Bounding Box) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet (Bounding Box)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0315",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the iNaturalist 2019 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"iNaturalist 2019\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0094",
            "query_type": "Non-factoid",
            "question": {
                "string": "Who are the co-authors of Kurt Thomas?"
            },
            "paraphrased_question": [
                "Who are the authors that Kurt Thomas has written research papers with?"
            ],
            "query": {
                "sparql": "SELECT ?co_authors\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers orkgp:P27 ?authors.\n  FILTER(REGEX(?authors, \"Kurt Thomas\"))\n  ?papers orkgp:P27 ?co_authors.\n  FILTER(?co_authors != \"Kurt Thomas\"^^xsd:string)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "star",
            "query_class": "WHAT-WHO",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1598",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy (2 classes) metric on the IMDb benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (2 classes)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1746",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 score metric on the BUCC Russian-to-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Russian-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0531",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the NCBI Disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NCBI Disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0432",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the IWSLT2015 English-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0326",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Sequential MNIST benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Sequential MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1330",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the WOS-11967 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-11967\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2368",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CeiT-T model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-T\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1951",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BERT-CRF model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BERT-CRF\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1811",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the ObjectNet (Bounding Box) dataset in terms of Top 5 Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 5 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet (Bounding Box)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0984",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the IMDb-M dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb-M\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2410",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CvT-21 (384 res, ImageNet-22k pretrain) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-21 (384 res, ImageNet-22k pretrain)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0116",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the SQuAD1.1 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD1.1 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1720",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Asterix benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1234",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Habitat 2020 Point Nav test-std dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2030",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Denoising autoencoders (non-autoregressive) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Denoising autoencoders (non-autoregressive)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0577",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Seaquest dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Seaquest\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0025",
            "query_type": "Factoid",
            "question": {
                "string": "Which scholarly knowledge graphs support RDF?"
            },
            "paraphrased_question": [
                " Which graphs have RDF support?",
                " What is the list of all graphs which are compatible with RDF?",
                " Which graphs are able to work with RDF?"
            ],
            "query": {
                "sparql": "SELECT ?title\nWHERE {\n  orkgr:R78023 orkgp:compareContribution ?cont.\n  ?cont orkgp:P7009 ?has_rdf.\n  FILTER(REGEX(?has_rdf, \"T\"))\n  ?cont rdfs:label ?title\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ2218",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the GR-ConvNet model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GR-ConvNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0266",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Up and Down dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Up and Down\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1485",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the SQuAD2.0 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD2.0\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0029",
            "query_type": "Factoid/Temporal/Count",
            "question": {
                "string": "How many studies are published after 2019?"
            },
            "paraphrased_question": [
                "What is the number of published studies from 2019 onwords?"
            ],
            "query": {
                "sparql": "SELECT (COUNT(?date) AS ?number_of_studies)\nWHERE {\n  orkgr:R110393 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P9040 ?date.\n  filter(?date > \"2019\"^^xsd:string)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ2128",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer (12 layers) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (12 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1278",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Demon Attack dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Demon Attack\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1167",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Winograd Schema Challenge dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Winograd Schema Challenge\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0546",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Cartpole, swingup (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1047",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the SciERC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciERC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1095",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the WLPC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WLPC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0328",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the BUCC German-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC German-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0714",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the CS-NER benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CS-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0636",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Yelp-2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0711",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the SciFACT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0066",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WLPC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WLPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1403",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the SciERC dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciERC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1297",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Asterix dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Asterix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1580",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Error score on the Amazon-2 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Amazon-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1258",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the X-Sum dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"X-Sum\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0231",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the GigaWord dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GigaWord\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2122",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Longformer (12 layers, h=512) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Longformer (12 layers, h=512)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2048",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the AVID model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVID\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0856",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the MRPC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MRPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0843",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Penn Treebank (Character Level) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Penn Treebank (Character Level)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0582",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari-57 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari-57\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0295",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the TREC-6 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TREC-6\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2198",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Grave et al. (2016) - LSTM + continuous cache pointer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Grave et al. (2016) - LSTM + continuous cache pointer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0210",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the FGVC Aircraft benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2270",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Universal Sentence Encoder model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Universal Sentence Encoder\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1714",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Venture dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1774",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the CUB-200-2011 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CUB-200-2011\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1033",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the AI-KG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AI-KG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1378",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the WebNLG dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WebNLG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2449",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Transformer (self-attention) (Trinh et al., 2018) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (self-attention) (Trinh et al., 2018)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1701",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Zaxxon benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Zaxxon\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2459",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Class Diagram model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Class Diagram\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1371",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Open Entity dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Open Entity\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0877",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Finger, spin (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1785",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Best Score metric on the Atari 2600 River Raid benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Best Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 River Raid\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0565",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the MLDoc Zero-Shot English-to-Spanish dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Spanish\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1641",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Walker, walk (DMControl500k) dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0283",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 James Bond dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1979",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the VPN model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VPN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0014",
            "query_type": "Non-factoid",
            "question": {
                "string": "What are the metrics used by paper \"Using NMF-based text summarization to improve supervised and unsupervised classification?"
            },
            "paraphrased_question": [
                "What evaluation metrics are used by the paper \"Using NMFbased text summarization to improve supervised and unsupervised classification?"
            ],
            "query": {
                "sparql": "SELECT ?metrics, ?metrics_labels\nWHERE {\n  ?papers rdfs:label ?title.\n  FILTER(REGEX(?title, \"NMF-based text summarization\"))\n  ?papers orkgp:P31 ?cont.\n  ?cont orkgp:P34 ?eval.\n  ?eval orkgp:P2006 ?metrics.\n  ?metrics rdfs:label ?metrics_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0189",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the BC5CDR dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1992",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the WDec model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"WDec\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2401",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CaiT-M-48-448 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CaiT-M-48-448\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1897",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Knowledge Graph Embedding research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Knowledge Graph Embedding\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2429",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Five Base + Five HiRes model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Five Base + Five HiRes\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0253",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Atari 2600 Kung-Fu Master benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Kung-Fu Master\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0405",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the SemEval-2010 Task 8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0122",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the SQuAD1.1 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD1.1\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0072",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the CIFAR-100 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0709",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the SciCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1966",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Hierarchical clustering model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Hierarchical clustering\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2148",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the GPT-3 (Zero-Shot) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GPT-3 (Zero-Shot)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1900",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the SPARQL query optimization research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"SPARQL query optimization\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2447",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the DATL model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DATL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1898",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Document Summarization research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Document Summarization\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1022",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the NLP-TDMS (Exp, arXiv only) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0059",
            "query_type": "Non-factoid/Superlative",
            "question": {
                "string": "Which are five the most common research fields for papers?"
            },
            "paraphrased_question": [
                "What are the top five used research fields in papers?"
            ],
            "query": {
                "sparql": "SELECT ?research_field, ?research_field_labels\nWHERE {\n  ?papers orkgp:P30 ?research_field.\n  ?research_field rdfs:label ?research_field_labels.\n}\nORDER BY DESC(COUNT(?research_field_labels))\nLIMIT 5"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ0700",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the SoMeSci dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SoMeSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2389",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the PyramidNet (SAM) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PyramidNet (SAM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1640",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Cartpole, swingup (DMControl100k) dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1797",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the WOS-11967 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-11967\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0365",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2334",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DQN-CTS model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN-CTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2066",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the DrQA (Document Reader only) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DrQA (Document Reader only)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2319",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the IDVQ + DRSC + XNES model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"IDVQ + DRSC + XNES\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1110",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset WMT2014 German-English?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0149",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the enwik8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"enwik8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1248",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the MLDoc Zero-Shot English-to-Japanese dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Japanese\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2116",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Compressive Transformer (24 layers) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Compressive Transformer (24 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0538",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Finger, spin (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0364",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the TDMSci dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TDMSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0949",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Time Pilot dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Time Pilot\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1779",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the Oxford-IIIT Pets benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0802",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the SQuAD1.1 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD1.1 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1038",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the AAN Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AAN Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2382",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CvT-W24 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-W24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0941",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Beam Rider dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Beam Rider\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1002",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the ImageNet V2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet V2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2305",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the DQN noop model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN noop\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0715",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the CORLL dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0044",
            "query_type": "Factoid/Count",
            "question": {
                "string": "What is the total number of species examined in the studies?"
            },
            "paraphrased_question": [
                "How many species are examined throughout the papers?"
            ],
            "query": {
                "sparql": "SELECT (SUM(?number) AS ?total)\nWHERE {\n  orkgr:R58002 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P31024 ?number_of_species.\n  BIND(xsd:integer(?number_of_species) AS ?number)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ1784",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Best Score score on the Atari 2600 Ms. Pacman benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Best Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Ms. Pacman\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1170",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the RTE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RTE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2169",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the GRU (Bai et al., 2018) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GRU (Bai et al., 2018)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0827",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the RTE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RTE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1848",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Triples extraction research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Triples extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1760",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Percentage error score on the MNIST benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0126",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Natural Questions (long) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions (long)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0913",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the WSC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WSC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1833",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the IMDb-B benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb-B\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0890",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Walker, walk (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0793",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Natural Questions (short) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions (short)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1152",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the CNN / Daily Mail dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CNN / Daily Mail\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1226",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Lunar Lander (OpenAI Gym)?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Lunar Lander (OpenAI Gym)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1520",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the QNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0121",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Story Cloze Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Story Cloze Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0775",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the IWSLT2015 English-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0036",
            "query_type": "Factoid",
            "question": {
                "string": "What is the full name of the EXPO ontology?"
            },
            "paraphrased_question": [
                "What does abbreviation \"EXPO\" in the title of corresponding ontology correspond?"
            ],
            "query": {
                "sparql": "SELECT ?full_name\nWHERE {\n  orkgr:R8342 orkgp:compareContribution ?cont.\n  ?cont orkgp:P7034 ?ontology.\n  ?ontology rdfs:label ?ont_lbl;\n            orkgp:P7035 ?full_name. \n  FILTER(REGEX(STR(?ont_lbl), \"expo\", \"i\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1975",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the AttentionOCR_Inception-resnet-v2_Location model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AttentionOCR_Inception-resnet-v2_Location\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0073",
            "query_type": "Factoid",
            "question": {
                "string": "Do all studies include open ocean sampling?"
            },
            "paraphrased_question": [
                "Is open ocean sampling involved in all contibutions?"
            ],
            "query": {
                "sparql": "ASK {\n  {\n    SELECT (COUNT(?ocean_sampling) AS ?counter)\n    WHERE {\n      orkgr:R155561 orkgp:compareContribution ?contrib.\n      ?contrib orkgp:P41379 ?ocean_sampling.\n      FILTER(?ocean_sampling = \"F\"^^xsd:string)\n    }\n  }\n  FILTER(?counter = 0)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "BOOLEAN",
            "number_of_patterns": 2
        },
        {
            "id": "AQ0967",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Boxing dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Boxing\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0256",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Freeway dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Freeway\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0286",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Video Pinball dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Video Pinball\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2281",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the PtGen-Covg model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PtGen-Covg\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1387",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of RE+ Macro F1  metric on the CoNLL04 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE+ Macro F1 \")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL04\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0820",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ARC (Challenge) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Challenge)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0746",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the GAD benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GAD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1608",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of PARAMS metric on the Stanford Cars benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Stanford Cars\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0561",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Reuters RCV1/RCV2 German-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 German-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0729",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the nuScenes dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"nuScenes\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2013",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SciBERT (Base Vocab) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT (Base Vocab)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1978",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the LSTM model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1739",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of PARAMS score when benchmarked on the Flowers-102 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Flowers-102\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0034",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Abstracts\\' entities and relations annotated corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1747",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Mean Accuracy score when benchmarked on the ModelNet40 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Mean Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ModelNet40\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1151",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SQuAD1.1 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD1.1\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0376",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Automatically labeled Medline abstracts corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0706",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the ner_dataset_recognition dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ner_dataset_recognition\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1311",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Space Invaders dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Space Invaders\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1846",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the co-authorship prediction research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"co-authorship prediction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1783",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the AAPD benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AAPD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1338",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the PubMed 20k RCT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PubMed 20k RCT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1616",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the One Billion Word dataset in terms of Validation perplexity metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Validation perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"One Billion Word\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1887",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Citation Intent Classification research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Citation Intent Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2202",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the PAR Transformer 24B model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PAR Transformer 24B\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0004",
            "query_type": "Factoid",
            "question": {
                "string": "Who is responsible for acquisition in the RASH system?"
            },
            "paraphrased_question": [
                "Who collected the data for the RASH system?"
            ],
            "query": {
                "sparql": "SELECT ?acq\nWHERE {\n  orkgr:R8364 orkgp:compareContribution ?cont.\n  ?cont orkgp:P7046 orkgr:R8350.\n  orkgr:R8350 orkgp:P7049 ?acq.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHO-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0855",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the SentEval dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SentEval\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0416",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the 200k Short Texts for Humor Detection dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"200k Short Texts for Humor Detection\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1255",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the MLDoc Zero-Shot English-to-Italian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0931",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Atlantis dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Atlantis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2416",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the CAIT-XXS-36 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-XXS-36\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0446",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the RACE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RACE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1562",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the SST-2 Binary classification benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SST-2 Binary classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1031",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset FTD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FTD dataset\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0458",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the CommonsenseQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0010",
            "query_type": "Non-factoid",
            "question": {
                "string": "What metric will be used to evaluate question answering systems?"
            },
            "paraphrased_question": [
                "With which metric are the question answering systems evaluated?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?name\nWHERE {\n  [\n    orkgp:P34 [\n      rdfs:label ?name \n    ]\n  ].\n  FILTER(STRLEN(?name) > 0)\n}\nORDER BY ?name"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ1674",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot German-to-French benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot German-to-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0171",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the GENIA - UAS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - UAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2084",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the SAN (single model) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SAN (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2434",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the ZFNet (1 convnet, 512,1024,512 maps) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ZFNet (1 convnet, 512,1024,512 maps)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1853",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Relation Classification research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Relation Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1865",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Word Sense Disambiguation research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Word Sense Disambiguation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1907",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Transformer-based One-Shot NAS (Neural Architecture Search) model. model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-based One-Shot NAS (Neural Architecture Search) model.\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0686",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the DocRED (Human-annotated) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DocRED (Human-annotated)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1007",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Flowers-102 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Flowers-102\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2286",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CGU model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CGU\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0894",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Dmlab-30 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2264",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BiLSTM (Europarl) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM (Europarl)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2245",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CURL model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CURL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1076",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Twitter?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Twitter\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2061",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BERTjoint model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BERTjoint\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0015",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What is the maximum sample size?"
            },
            "paraphrased_question": [
                "How large is the largest sample size?"
            ],
            "query": {
                "sparql": "SELECT ?sample_size\nWHERE {\n  orkgr:R135371 orkgp:compareContribution ?cont.\n  ?cont orkgp:P15687 ?sample_size\n}\nORDER BY DESC(?sample_size)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ1876",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Medical Named Entity Recognition research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Medical Named Entity Recognition\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0274",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Montezuma\\'s Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Montezuma\\'s Revenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0532",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the BC5CDR dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1558",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of PRE-TRAINING DATASET score when benchmarked on the ESC-50 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PRE-TRAINING DATASET\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ESC-50\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0510",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the CoNLL 2012 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2012\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1686",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of ROUGE-L metric on the AESLC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-L\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AESLC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1380",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 score when benchmarked on the NYT29 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT29\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2364",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CaiT-M-36 U 224 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CaiT-M-36 U 224\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1769",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Percentage error metric on the Fashion-MNIST benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Fashion-MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2101",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Neural Content Planning + conditional copy model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Neural Content Planning + conditional copy\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2260",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the MultiFiT, pseudo model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MultiFiT, pseudo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1942",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the SciNLP-KG model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciNLP-KG\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0747",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ChemProt dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ChemProt\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0862",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the UrbanSound8k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UrbanSound8k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1599",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CIFAR-10 dataset in terms of Parameters metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Parameters\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1630",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Walker, walk (DMControl100k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0822",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the OpenBookQA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OpenBookQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0629",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Video Pinball dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Video Pinball\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0030",
            "query_type": "Factoid",
            "question": {
                "string": "Which toxins do pseudomonas species produce?"
            },
            "paraphrased_question": [
                "What is the list of the toxins produced by pseudomonas species?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?toxins, ?toxins_labels\nWHERE {\n  orkgr:R69027 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P34037 ?toxins.\n  ?toxins rdfs:label ?toxins_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0196",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Reacher, easy (DMControl500k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1133",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the CUB-200-2011 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CUB-200-2011\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0688",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the FTD dataset benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FTD dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0485",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MultiNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MultiNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0557",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the CIFAR-10 Image Classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10 Image Classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1346",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Kuzushiji-MNIST?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1899",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Atari Games research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Atari Games\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1890",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Music Modeling research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Music Modeling\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1646",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest DISTANCE_TO_GOAL score on the Habitat 2020 Object Nav test-std benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"DISTANCE_TO_GOAL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0886",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Cart Pole (OpenAI Gym) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cart Pole (OpenAI Gym)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1339",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SciCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2195",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the SRU++ model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SRU++\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0207",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Gibson PointGoal Navigation benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Gibson PointGoal Navigation\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2259",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Bi+ model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Bi+\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0038",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Car speed in Liuliqiao District, Beijing dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Car speed in Liuliqiao District, Beijing\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0035",
            "query_type": "Factoid",
            "question": {
                "string": "Which scenario factsheets from the Open Energy Platform are used in studies with public funding?"
            },
            "paraphrased_question": [
                " Which Open Energy Platform factsheets are used in the publicly funded studies?",
                " What is the list of those Open Energy Platform scenario factsheets which are exploited in the studies with public funding ?"
            ],
            "query": {
                "sparql": "SELECT ?paper\nWHERE {\n  orkgr:R113171 orkgp:compareContribution ?cont.\n  ?paper orkgp:P31 ?cont.\n  ?cont orkgp:P37586 ?hasFacts.\n  ?hasFacts orkgp:P37675 ?study.\n  ?study orkgp:P37663 ?sourceOfFunding.\n  FILTER(REGEX(?sourceOfFunding, \"public\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1612",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy (%) score when benchmarked on the Oxford 102 Flowers dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0139",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Supervised: dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Supervised:\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1122",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Fashion-MNIST?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Fashion-MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1511",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the CommitmentBank benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CommitmentBank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2370",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the LeViT-192 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LeViT-192\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0180",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Yelp Binary classification benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp Binary classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1056",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the SciGEN dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciGEN\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1055",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SciTLDR dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciTLDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2134",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the All-attention network (36 layers) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"All-attention network (36 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0046",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the FB15k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FB15k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0137",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the ARC (Easy) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1393",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest NER Micro F1 score on the ACE 2005 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0596",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Kung-Fu Master dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Kung-Fu Master\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1943",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the S-NLI model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"S-NLI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0650",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Reuters En-De dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters En-De\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0354",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the ORKG-TDM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1828",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Micro Precision score when benchmarked on the NLP-TDMS (Exp, arXiv only) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0366",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SciCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2458",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Relationship Types model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Relationship Types\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1183",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset The Pile?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"The Pile\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1462",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1a score when benchmarked on the MultiRC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1a\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MultiRC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1432",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of BLEU metric on the WMT2016 English-German benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0763",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the WMT2016 English-Czech benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Czech\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0482",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Supervised: dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Supervised:\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0400",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the CoNLL04 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL04\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1801",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Yelp-14 dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-14\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0728",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1126",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Multimodal PISA?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Multimodal PISA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2027",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CMLM+LAT+4 iterations model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CMLM+LAT+4 iterations\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1061",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Annotated development corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Annotated development corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0539",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Reacher, easy (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0920",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Seaquest benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Seaquest\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1089",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset GAD?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GAD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1243",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the CIFAR-10 Image Classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10 Image Classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0088",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the WMT2016 Romanian-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Romanian-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0192",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Ball in cup, catch (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0427",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the IWSLT2015 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0959",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Tennis dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Tennis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0247",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Zaxxon dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Zaxxon\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0362",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SemEval-2021 Task 11 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2021 Task 11\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0895",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the ClueWeb09-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ClueWeb09-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2384",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DeiT-B model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DeiT-B\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1010",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Birdsnap dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Birdsnap\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1383",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 entity level score when benchmarked on the JNLPBA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 entity level\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"JNLPBA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2417",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CvT-13-NAS model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-13-NAS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1757",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Gravitar benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1401",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the SemEval-2010 Task 8 dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0528",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the CoNLL++ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL++\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2431",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DY-MobileNetV2 \u00d70.35 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-MobileNetV2 \u00d70.35\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1940",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the CitClus model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CitClus\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0549",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Habitat 2020 Object Nav test-std dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0937",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Amidar dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0054",
            "query_type": "Non-factoid/Ranking",
            "question": {
                "string": "What is the minimum and maximum installed capacity for each energy source considered?"
            },
            "paraphrased_question": [
                "What are extreme values of installed capacity grouped by energy source?"
            ],
            "query": {
                "sparql": "SELECT ?energy_sources_labels (MIN(?installed_cap_value) AS ?min_installed_cap_value) (MAX(?installed_cap_value) AS ?max_installed_cap_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43133 ?installed_capacity.\n  ?installed_capacity orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?installed_cap_value)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2463",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list benchmarked problems in the area of Computer Sciences?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?problem ?problem_lbl\nWHERE {\n  ?rf       a            orkgc:ResearchField;\n            rdfs:label   ?rf_label.\n  FILTER (str(?rf_label) = \"Computer Sciences\")\n  ?paper    orkgp:P30    ?rf;\n            orkgp:P31    ?cont.\n  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                orkgp:P32                ?problem.\n  ?problem      rdfs:label               ?problem_lbl.\n}"
            },
            "template_id": "T08",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0065",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the ADE Corpus benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1586",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the Paper Field benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Paper Field\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1906",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the RNN model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"RNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0655",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the ScienceCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ScienceCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0430",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the WMT2016 Czech-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Czech-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0751",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the ADE Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0049",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Penn Treebank dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Penn Treebank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1667",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy (%) score when benchmarked on the DTD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DTD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2212",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the All-attention network - 36 layers model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"All-attention network - 36 layers\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2159",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Trellis Network model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Trellis Network\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1427",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest BLEU score on the WMT2016 German-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2161",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Transformer-XL model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0800",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the BoolQ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BoolQ\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0765",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the WMT2016 English-Romanian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Romanian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1254",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset MLDoc Zero-Shot English-to-French?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1724",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Frostbite benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0884",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Cartpole, swingup (DMControl500k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0221",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the MLDoc Zero-Shot German-to-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot German-to-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1261",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the CL-SciSumm dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CL-SciSumm\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2186",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the AWD-LSTM-MoS + ATOI model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-MoS + ATOI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1594",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Open Entity dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Open Entity\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1670",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Reuters RCV1/RCV2 English-to-German dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 English-to-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0631",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Star Gunner dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Star Gunner\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0754",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the DDI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0749",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the NYT-single dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT-single\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1080",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the WebNLG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WebNLG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0056",
            "query_type": "Non-factoid/Count",
            "question": {
                "string": "What is the average installed capacity for each energy source considered in 5 year intervals?"
            },
            "paraphrased_question": [
                "What are the mean values of installed capacity for 5 years intervals grouped by energy source ?"
            ],
            "query": {
                "sparql": "SELECT ?rangeId ?energy_sources_labels (AVG(?installed_cap_value AS ?avg_installed_cap_value))\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?paper orkgp:P31 ?contrib;\n         orkgp:P29 ?year.\n  BIND(xsd:int(?year) AS ?y).\n  VALUES(?rangeId ?min ?max) {\n    (\"2001-2005\" 2001 2005)\n    (\"2006-2010\" 2006 2010)\n    (\"2011-2015\" 2011 2015)\n    (\"2016-2020\" 2016 2020)\n  }\n  FILTER(?min <= ?y && ?y <= ?max).\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43133 ?installed_capacity.\n  ?installed_capacity orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?installed_cap_value).\n}\nORDER BY ASC(?rangeId)"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 7
        },
        {
            "id": "AQ0901",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the DTD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DTD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1946",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the end-to-end relation extraction model model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"end-to-end relation extraction model\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0787",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the HMDB51 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1825",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the NLP-TDMS (Exp, arXiv only) dataset in terms of Micro F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1915",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the HNEABP (BWEL) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"HNEABP (BWEL)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1266",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Crazy Climber?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Crazy Climber\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1572",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 score when benchmarked on the BC5CDR dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0042",
            "query_type": "Non-factoid",
            "question": {
                "string": "Who is the author of the most recent paper about insects?"
            },
            "paraphrased_question": [
                "By whom the lattest study about insects was undertaken?"
            ],
            "query": {
                "sparql": "SELECT ?author_name\nWHERE {\n  {\n    SELECT ?publication_date_ AS ?date_of_the_latest_paper {\n      ?paper_ a orkgc:Paper;\n              rdfs:label ?title_;\n              orkgp:P28 ?publication_month_;\n              orkgp:P29 ?publication_year_.\n      OPTIONAL {\n        ?publication_month_ rdfs:label ?publication_month_label_\n      }\n      OPTIONAL {\n        ?publication_year_ rdfs:label ?publication_year_label_\n      }\n      BIND(\n        xsd:integer(\n          IF(\n            BOUND(?publication_month_label_),\n            ?publication_month_label_,\n            ?publication_month_\n          )\n        ) AS ?publication_month_as_number_\n      )\n      BIND(\n        xsd:integer(\n          IF(\n            BOUND(?publication_year_label_),\n            ?publication_year_label_,\n            ?publication_year_\n          )\n        ) AS ?publication_year_as_number_\n      )\n      BIND(\n        xsd:dateTime(\n          CONCAT(\n            ?publication_year_as_number_,\n            \"-\",\n            ?publication_month_as_number_,\n            \"-01T00:00:00.000-00:00\"\n          )\n        )\n        AS ?publication_date_\n      )\n      FILTER(\n        ?publication_month_as_number_ > 0 && ?publication_month_as_number_ < 13 && ?publication_year_as_number_ > 0 && ?publication_year_as_number_ < 2023\n      )\n      FILTER(REGEX(STR(?title_), \"insect\"))\n    }\n    ORDER BY DESC(?publication_date_)\n    LIMIT 1\n  }\n  ?paper a orkgc:Paper;\n           rdfs:label ?title;\n           orkgp:P27 ?author;\n           orkgp:P28 ?publication_month;\n           orkgp:P29 ?publication_year.\n  OPTIONAL {\n     ?publication_month rdfs:label ?publication_month_label\n  }\n  OPTIONAL {\n    ?publication_year rdfs:label ?publication_year_label\n  }\n  OPTIONAL {\n    ?author rdfs:label ?author_label\n  }\n  BIND(\n    IF(\n      BOUND(?author_label),\n      ?author_label,\n      ?author\n    ) AS ?author_name\n  )\n  BIND(\n    xsd:integer(\n      IF(\n        BOUND(?publication_month_label),\n        ?publication_month_label,\n        ?publication_month\n      )\n    ) AS ?publication_month_as_number\n  )\n  BIND(\n    xsd:integer(\n      IF(\n        BOUND(?publication_year_label),\n        ?publication_year_label,\n        ?publication_year\n      )\n    ) AS ?publication_year_as_number\n  )\n  BIND(\n    xsd:dateTime(\n      CONCAT(\n        ?publication_year_as_number,\n        \"-\",\n        ?publication_month_as_number,\n        \"-01T00:00:00.000-00:00\"\n      )\n    )\n    AS ?publication_date\n  )\n  FILTER(\n    ?publication_month_as_number > 0 && ?publication_month_as_number < 13 && ?publication_year_as_number > 0 && ?publication_year_as_number < 2023\n  )\n  FILTER(\n    REGEX(\n      STR(?title),\n      \"insect\"\n    ) && ?publication_date = ?date_of_the_latest_paper\n  )\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "forest",
            "query_class": "WHO-WHAT",
            "number_of_patterns": 14
        },
        {
            "id": "AQ1280",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Amidar dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0019",
            "query_type": "Factoid/",
            "question": {
                "string": "Does \"PRISMA hyperspectral mission\" use ENVI software?"
            },
            "paraphrased_question": [
                "Does the paper \"paper title\" uses ENVI software?"
            ],
            "query": {
                "sparql": "SELECT ?uses_ENVI\nWHERE {\n  ?papers rdfs:label ?titles.\n  FILTER(REGEX(?titles, \"PRISMA\"))\n  ?papers orkgp:P31 ?cont.\n  ?cont orkgp:P23031 ?software.\n  ?software rdfs:label ?software_labels.\n  BIND(\n    IF(?software_labels = \"ENVI\"^^<http://www.w3.org/2001/XMLSchema#string>, \"Yes\", \"No\") \n    AS ?uses_ENVI\n  )\n}\nORDER BY DESC(?uses_ENVI)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0087",
            "query_type": "Non-factoid/Superlative",
            "question": {
                "string": "When the earliest paper related to X-rays was published? "
            },
            "paraphrased_question": [
                "What is the date of the first paper related to XRays?"
            ],
            "query": {
                "sparql": "SELECT ?publication_years\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers rdfs:label ?papers_labels.\n  FILTER(REGEX(?papers_labels, \"X-ray\", \"i\"))\n  ?papers orkgp:P29 ?publication_years. \n}\nORDER BY ASC(?publication_years)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "star",
            "query_class": "WHAT-WHEN",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1539",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Number of params score when benchmarked on the Text8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1590",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the ScienceCite benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ScienceCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0041",
            "query_type": "Factoid",
            "question": {
                "string": "What can one use instead of wheat flour?"
            },
            "paraphrased_question": [
                "What can be used as a substitute for wheat flour in composite bread?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?flour\nWHERE {\n  ?_ orkgp:P37571 ?flour.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "edge",
            "query_class": "WHAT-WHEN",
            "number_of_patterns": 1
        },
        {
            "id": "AQ2104",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Hierarchical transformer encoder + conditional copy model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Hierarchical transformer encoder + conditional copy\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1731",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 James Bond dataset in terms of Medium Human-Normalized Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1703",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Demon Attack dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Demon Attack\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0055",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the JNLPBA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"JNLPBA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1207",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Yelp Fine-grained classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp Fine-grained classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0028",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the CS-NER dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CS-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2056",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the GPT-3 (few-shot) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GPT-3 (few-shot)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1162",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the RotoWire dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1049",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ner_dataset_recognition dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ner_dataset_recognition\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1045",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset ScienceIE?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ScienceIE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1374",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the IMDb dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IMDb\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1158",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the One Billion Word dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"One Billion Word\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2398",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BiLSTM-TDN(ResNet-101) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-TDN(ResNet-101)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1518",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of % Train Accuracy metric on the SNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"% Train Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1479",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CNN / Daily Mail dataset in terms of ROUGE-1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CNN / Daily Mail\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2153",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the AWD-LSTM-MoS + dynamic eval model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-MoS + dynamic eval\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0086",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WMT2016 Russian-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Russian-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1982",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the GRU model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GRU\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2036",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer Base + adversarial MLE model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer Base + adversarial MLE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0529",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the CoNLL 2003 (English) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2003 (English)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0873",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the BC5CDR-disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1398",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Micro F1 score when benchmarked on the GAD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GAD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0381",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Car speed in Liuliqiao District, Beijing dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Car speed in Liuliqiao District, Beijing\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1791",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 HERO dataset in terms of Best Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Best Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 HERO\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0657",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the VTAB-1k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"VTAB-1k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0846",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the BIOSSES benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BIOSSES\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0257",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Atari 2600 Alien benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Alien\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2076",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Reading Twice for NLU model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Reading Twice for NLU\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1413",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the AG News dataset in terms of Error metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AG News\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0034",
            "query_type": "Factoid/Count",
            "question": {
                "string": "How many studies do use Chloride as major anion?"
            },
            "paraphrased_question": [
                "What is the number of studies that make use of Chloride as a major anion?"
            ],
            "query": {
                "sparql": "SELECT COUNT(?anions_labels) AS ?chloride_count\nWHERE {\n  orkgr:R110597 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37458 ?anions.\n  ?anions rdfs:label ?anions_labels.\n  FILTER(REGEX(?anions_labels, \"Chloride\"^^xsd:string))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1211",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the NCBI-disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NCBI-disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0429",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the WMT2016 Russian-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Russian-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0541",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Cartpole, swingup (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1759",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the MNIST benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1799",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the WOS-46985 dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-46985\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2316",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Prior+Duel noop model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prior+Duel noop\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1672",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the MLDoc Zero-Shot English-to-Japanese benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Japanese\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2146",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Large mLSTM +emb +WN +VD model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Large mLSTM +emb +WN +VD\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0585",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Pong dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1259",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the arXiv dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"arXiv\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0377",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Abstracts\\' entities and relations annotated corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2090",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Document Reader (single model) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Document Reader (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1177",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the QNLI dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2047",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the XDC model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XDC\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1753",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Phoenix benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2323",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Rainbow DQN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Rainbow DQN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2298",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the DDQN (tuned) hs model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DDQN (tuned) hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0033",
            "query_type": "Non-factoid",
            "question": {
                "string": "What risk factors for OSA are discovered in the paper with 100% OSA frequency?  "
            },
            "paraphrased_question": [
                "What is the list of risk factors for obstuctive sleep apnea mentioned in papers with a 100% OSA ferquency?"
            ],
            "query": {
                "sparql": "SELECT ?risk_factors, ?risk_factors_labels\nWHERE {\n  orkgr:R110932 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37530 ?osa_frequency.\n  ?osa_frequency rdfs:label ?osa_frequency_values.\n  ?contrib orkgp:P37528 ?risk_factors.\n  ?risk_factors rdfs:label ?risk_factors_labels.\n  FILTER(REGEX(?osa_frequency_values, \"100\"^^xsd:string))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1617",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Bit per Character (BPC) score on the enwiki8 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bit per Character (BPC)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwiki8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2354",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the SciBERT model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0455",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the MultiRC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MultiRC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0244",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Centipede dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Centipede\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0737",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the WebNLG benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0693",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ACL Anthology dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL Anthology\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0374",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ART/CoreSC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ART/CoreSC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1210",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the SST-2 Binary classification dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SST-2 Binary classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1917",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Extended Transformer Construction model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Extended Transformer Construction\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2307",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the A2C + SIL model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"A2C + SIL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0739",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the NYT29 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT29\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0170",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the MRPC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MRPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0927",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Pitfall! benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Pitfall!\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0710",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Dataset mentions in Social Sciences benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Dataset mentions in Social Sciences\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1399",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Micro F1 score when benchmarked on the ChemProt dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ChemProt\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1655",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy (%) score when benchmarked on the Oxford-IIIT Pets dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0158",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Text8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Text8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0812",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Natural Questions (long) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions (long)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1470",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the Quora Question Pairs benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Quora Question Pairs\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1154",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SQuAD2.0 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD2.0 dev\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1058",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the CORLL dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CORLL\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0345",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the FTD dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FTD dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1765",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the 20NEWS benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"20NEWS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1626",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy (10-fold) metric on the UrbanSound8k benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (10-fold)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UrbanSound8k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0804",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Quora Question Pairs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Quora Question Pairs\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0806",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the TriviaQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TriviaQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0553",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the FGVC Aircraft dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1683",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the GigaWord dataset in terms of ROUGE-1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GigaWord\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1215",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the CoNLL 2003 (English) dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL 2003 (English)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1202",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset AudioSet?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AudioSet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1014",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the BUCC German-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC German-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2181",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Rfa-Gate-Gaussian-Stateful (Big) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Rfa-Gate-Gaussian-Stateful (Big)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1435",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of BLEU score score when benchmarked on the WMT2016 Czech-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 Czech-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0232",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the CL-SciSumm dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CL-SciSumm\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0197",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Lunar Lander (OpenAI Gym) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Lunar Lander (OpenAI Gym)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1889",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Conversational Response Selection research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Conversational Response Selection\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1450",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy (Middle) score when benchmarked on the RACE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (Middle)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RACE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0350",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ACL Anthology dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL Anthology\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0220",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the MLDoc Zero-Shot English-to-German benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1659",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of FLOPS score when benchmarked on the CINIC-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CINIC-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1102",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset 200k Short Texts for Humor Detection?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"200k Short Texts for Humor Detection\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1083",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the NYT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0019",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the SemEval-2021 Task 11 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2021 Task 11\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0060",
            "query_type": "Non-factoid",
            "question": {
                "string": "What are economics subfields?"
            },
            "paraphrased_question": [
                "Which are the subfields of Economics research field?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?subfields, ?subfields_labels\nWHERE {\n  ?papers orkgp:P30 ?research_fields.\n  ?research_fields rdfs:label \"Economics\"^^xsd:string.\n  ?research_fields orkgp:P36 ?subfields.\n  ?subfields rdfs:label ?subfields_labels. \n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1364",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset PWC Leaderboards (restricted)?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1962",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CRFSuite model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CRFSuite\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2141",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the 64-layer Character Transformer Model model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"64-layer Character Transformer Model\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0866",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Yelp Binary classification benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp Binary classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0096",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Kinetics-600 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Kinetics-600\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0540",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Lunar Lander (OpenAI Gym) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Lunar Lander (OpenAI Gym)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0702",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the ScienceIE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ScienceIE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0887",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Ball in cup, catch (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0720",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Abstracts\\' entities and relations annotated corpus benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0687",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the SemEval-2018 Task 7 dataset benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2018 Task 7 dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1584",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Micro F1 metric on the HoC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HoC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1295",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Up and Down dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Up and Down\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1721",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 Ice Hockey dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Ice Hockey\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0386",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the nuScenes dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"nuScenes\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2003",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Multi-turn QA model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Multi-turn QA\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0048",
            "query_type": "Factoid/Ranking",
            "question": {
                "string": "What is the maximum female percentage?"
            },
            "paraphrased_question": [
                "What is the highest percentage of females?"
            ],
            "query": {
                "sparql": "SELECT ?female_percantage\nWHERE {\n  orkgr:R44978 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P23154 ?female_percantage.\n}\nORDER BY DESC(?female_percantage)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ2461",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list benchmarked problems in the area of Semantic Web?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?problem ?problem_lbl\nWHERE {\n  ?rf       a            orkgc:ResearchField;\n            rdfs:label   ?rf_label.\n  FILTER (str(?rf_label) = \"Semantic Web\")\n  ?paper    orkgp:P30    ?rf;\n            orkgp:P31    ?cont.\n  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                orkgp:P32                ?problem.\n  ?problem      rdfs:label               ?problem_lbl.\n}"
            },
            "template_id": "T08",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2329",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Rainbow model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Rainbow\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0610",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Wizard of Wor dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Wizard of Wor\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0133",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the RotoWire dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2325",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the C51 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"C51\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0679",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the NLP-TDMS (Exp, arXiv only) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0716",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the MAZEA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MAZEA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2165",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the NAS Cell model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NAS Cell\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1060",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the ART/CoreSC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ART/CoreSC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2054",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the AVID (Modified R2+1D-18 on Kinetics) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVID (Modified R2+1D-18 on Kinetics)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0145",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the MedNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1877",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Continuous Control research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Continuous Control\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1642",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of DISTANCE_TO_GOAL metric on the Habitat 2020 Point Nav test-std benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"DISTANCE_TO_GOAL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0084",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the IWSLT2015 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0973",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Chopper Command dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Chopper Command\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1423",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the WMT2016 English-Romanian dataset in terms of BLEU metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-Romanian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1039",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset TSE-NER?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TSE-NER\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0020",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "Which ontology has the most classes?"
            },
            "paraphrased_question": [
                "Which ontology has the largest number of classes?"
            ],
            "query": {
                "sparql": "SELECT ?ont ?ont_label\nWHERE {\n  orkgr:R8342 orkgp:compareContribution ?cont.\n  ?cont orkgp:P7034 ?ont.\n  ?ont orkgp:P7038 ?cls_cnt;\n       rdfs:label ?ont_label.\n}\nORDER BY DESC(MAX(xsd:int(?cls_cnt)))\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2010",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the PubMedBERT uncased model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PubMedBERT uncased\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2191",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the GCNN-8 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GCNN-8\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2428",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the DY-ResNet-10 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-ResNet-10\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0396",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the NYT29 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT29\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1135",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Quasart-T dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Quasart-T\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1830",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the MUTAG benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MUTAG\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2172",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Compressive Transformer (18L, M=1024) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Compressive Transformer (18L, M=1024)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0338",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the REDDIT-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"REDDIT-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1235",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Habitat 2020 Object Nav test-std?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0343",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the DocRED (Human-annotated) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DocRED (Human-annotated)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1954",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Zero-shot VERISCI model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Zero-shot VERISCI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0917",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the GigaWord dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GigaWord\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1526",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Hutter Prize dataset in terms of Bit per Character (BPC) metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bit per Character (BPC)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Hutter Prize\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1874",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Environmental Sound Classification research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Environmental Sound Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1467",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of EM score when benchmarked on the SQuAD1.1 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD1.1 dev\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2394",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DeiT-B-384 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DeiT-B-384\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0347",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the AI-KG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AI-KG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0794",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the DROP Test benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DROP Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1463",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Overall score when benchmarked on the CoQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Overall\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0062",
            "query_type": "Non-factoid",
            "question": {
                "string": "What are the objectives for Sepsis prediction?"
            },
            "paraphrased_question": [
                "What can Spesis prediction be used for?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?objectives\nWHERE {\n  orkgr:R70642 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15051 ?objectives.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ0290",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Robotank dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0382",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the seel.cse.lsu.edu/data/refsq17.zip dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"seel.cse.lsu.edu/data/refsq17.zip\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1815",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the ObjectNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2278",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Baseline : Extractive Oracle model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Baseline : Extractive Oracle\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0625",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Space Invaders dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Space Invaders\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2219",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the ResNet50 multi-grasp predictor model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ResNet50 multi-grasp predictor\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1164",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset PIQA?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PIQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1999",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Deeper model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Deeper\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2151",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the AWD-LSTM-DOC x5 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-DOC x5\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1111",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the WMT2016 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1419",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the WMT2014 French-English dataset in terms of BLEU metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2026",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the SMT + iterative backtranslation (unsupervised) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SMT + iterative backtranslation (unsupervised)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0177",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the SST-5 Fine-grained classification benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SST-5 Fine-grained classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2217",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Unregularised mLSTM model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Unregularised mLSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1716",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Bank Heist benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Bank Heist\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2377",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Zhao et al. (2015) (auto-encoder) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Zhao et al. (2015) (auto-encoder)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2158",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the AWD-LSTM-MoS + Partial Shuffle model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-MoS + Partial Shuffle\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0352",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the AAN Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AAN Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0858",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the GENIA - LAS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0831",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the MedNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1442",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of 3-fold Accuracy metric on the UCF101 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"3-fold Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0462",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the COPA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"COPA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1610",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of FLOPS score when benchmarked on the STL-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0922",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Gopher dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1196",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the CoNLL 2012 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL 2012\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1189",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the BIOSSES dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BIOSSES\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2333",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the TRPO-hash model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"TRPO-hash\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0024",
            "query_type": "Factoid",
            "question": {
                "string": "What is the research problem addressed by paper \"LIMSI participant at QADL-5@CLEF\"?"
            },
            "paraphrased_question": [
                "Which research problem does the paper \"paper title\" address?"
            ],
            "query": {
                "sparql": "SELECT ?problem ?problem_lbl\nWHERE {\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?paper_title.\n  ?cont orkgp:P32 ?problem.\n  ?problem rdfs:label ?problem_lbl.\n  FILTER(REGEX(STR(?paper_title), \"LIMSI participation at QALD-5@CLEF\", \"i\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2453",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the TDMS-IE model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"TDMS-IE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0668",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the STL-10, 1000 Labels dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STL-10, 1000 Labels\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0005",
            "query_type": "Factoid",
            "question": {
                "string": "What research problem is addressed in the paper titled \"6th Open Challenge on Question Answering over Linked Data (QALD-6)\"?\n"
            },
            "paraphrased_question": [
                "What reseach problem is the paper \"paper title\" trying to address?",
                "What is the aim of the research paper \"paper title\"?",
                "What is the aim of \"paper title\"?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?concept ?rlabel \nWHERE {\n  orkgr:R6386 orkgp:P31 ?x .\n  ?x orkgp:P32 ?concept.\n  ?concept rdfs:label ?rlabel.\n}\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0830",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the ANLI test benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ANLI test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1502",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest SemEval 2007 score on the Supervised: benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SemEval 2007\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Supervised:\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1582",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the Yelp-2 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0757",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the CIFAR-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1334",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Reuters De-En dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters De-En\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1200",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset GENIA - UAS?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"GENIA - UAS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0595",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Asteroids dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Asteroids\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2149",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BERT-Large-CAS model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BERT-Large-CAS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0394",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the WebNLG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebNLG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0910",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-Chinese dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Chinese\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1671",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the Reuters RCV1/RCV2 German-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 German-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1613",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of FLOPS metric on the Oxford 102 Flowers benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1256",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the WSC dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WSC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2111",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Nystr\u00f6mformer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Nystr\u00f6mformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1793",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the Ohsumed benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Ohsumed\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0957",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Ice Hockey benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Ice Hockey\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1772",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Top-1 Error Rate score when benchmarked on the Oxford 102 Flowers dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Error Rate\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2230",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Audio model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Audio\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1663",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Food-101 dataset in terms of PARAMS metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Food-101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2224",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Ning et al. model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Ning et al.\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1819",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Micro F1 score when benchmarked on the PWC Leaderboards (restricted) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0051",
            "query_type": "Non-Factoid/Count",
            "question": {
                "string": "What is the average energy generation for each energy source considered?"
            },
            "paraphrased_question": [
                "What is the mean value of energy generation for each energy source in the studies?"
            ],
            "query": {
                "sparql": "SELECT ?energy_sources_labels (AVG(?elec_gen_value) AS ?average_elec_gen_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43134 ?elec_gen.\n  ?elec_gen orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?elec_gen_value)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1315",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Video Pinball?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Video Pinball\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1758",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Robotank benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2020",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Ours: cross-sentence model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Ours: cross-sentence\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1438",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest BLEU score score on the IWSLT2015 English-German benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0520",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SST-5 Fine-grained classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SST-5 Fine-grained classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1851",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Part-Of-Speech Tagging research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Part-Of-Speech Tagging\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0058",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the ACE 2004 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACE 2004\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2275",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the PEGASUSLARGE model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PEGASUSLARGE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1869",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Temporal Information Extraction research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Temporal Information Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1738",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest FLOPS score on the Flowers-102 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Flowers-102\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2228",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the XLNet-Large (ensemble) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLNet-Large (ensemble)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1754",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 James Bond benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0453",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Natural Questions dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1264",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Name This Game?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Name This Game\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0070",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the AG News dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AG News\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0451",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the DROP Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DROP Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1288",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Solaris dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1575",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest ERR@20 score on the ClueWeb09-B benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ERR@20\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ClueWeb09-B\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0643",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Recipe dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Recipe\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2005",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DYGIE model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DYGIE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2052",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the AVID (Modified R2+1D-18 on Audioset) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AVID (Modified R2+1D-18 on Audioset)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2029",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the NAT +FT + NPD model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NAT +FT + NPD\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0651",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Paper Field dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Paper Field\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0659",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the ImageNet V2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet V2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0579",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Gopher dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0904",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Reuters RCV1/RCV2 German-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 German-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1707",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Kung-Fu Master benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Kung-Fu Master\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1100",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the CIFAR-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0594",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Amidar dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1500",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the ARC (Easy) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0578",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Name This Game dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Name This Game\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1457",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the PubMedQA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PubMedQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2220",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Multi-Modal Grasp Predictor model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Multi-Modal Grasp Predictor\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0506",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the  Jacquard dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \" Jacquard dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0644",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the WOS-11967 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-11967\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2171",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer-XL (SGD dynamic eval) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL (SGD dynamic eval)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2145",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the 3-layer AWD-LSTM model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"3-layer AWD-LSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0078",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the IWSLT2014 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1034",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset SciREX?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciREX\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2301",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Bootstrapped DQN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Bootstrapped DQN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1027",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Nottingham dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Nottingham\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2156",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the AWD-LSTM-DOC model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-DOC\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0617",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Montezuma\\'s Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Montezuma\\'s Revenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1831",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the REDDIT-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"REDDIT-B\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1239",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the FGVC Aircraft dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2379",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Weighted Tsetlin Machine model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Weighted Tsetlin Machine\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0150",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the LAMBADA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"LAMBADA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2170",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Transformer-XL (RMS dynamic eval) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL (RMS dynamic eval)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2371",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the LeViT-128 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LeViT-128\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1356",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Sequential CIFAR-10 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Sequential CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2041",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SMT model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1591",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Bits per byte metric on the Classical music, 5 seconds at 12 kHz benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bits per byte\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Classical music, 5 seconds at 12 kHz\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0839",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the WikiText-103 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-103\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0745",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the ACE 2005 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACE 2005\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1436",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of BLEU score when benchmarked on the WMT2016 Romanian-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 Romanian-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1822",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the PWC Leaderboards (restricted) dataset in terms of Micro Precision metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0795",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the PubMedQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PubMedQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0928",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Pong dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Pong\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1316",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Chopper Command dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Chopper Command\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2140",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the 18-layer Transformer-XL model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"18-layer Transformer-XL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1185",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset enwiki8?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwiki8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0117",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WebQuestions dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WebQuestions\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1605",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Percentage Error score when benchmarked on the CIFAR-100 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1547",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest MRPC score on the SentEval benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"MRPC\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0079",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the WMT2016 English-Romanian benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Romanian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0173",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the AudioSet benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AudioSet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2032",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Linguistic Input Features model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linguistic Input Features\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0342",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Open Entity dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Open Entity\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0227",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WSC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WSC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2107",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the ELMo model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ELMo\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1117",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the WMT2016 Romanian-English dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 Romanian-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2058",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Sparse Attention model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sparse Attention\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1852",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Relation Extraction research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Relation Extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1625",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Temporal awareness metric on the TempEval-3 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Temporal awareness\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TempEval-3\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1314",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Q*Bert?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Q*Bert\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1274",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Atlantis dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Atlantis\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0411",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the DDI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1147",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Quora Question Pairs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Quora Question Pairs\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0075",
            "query_type": "Factoid/Count",
            "question": {
                "string": "What is the average efficency for experiments?"
            },
            "paraphrased_question": [
                "What mean efficency is obtained for the studies?"
            ],
            "query": {
                "sparql": "SELECT AVG(?efficency_values)\nWHERE {\n  orkgr:R155266 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43156 ?efficency.\n  ?efficency rdfs:label ?efficency_labels.\n  BIND(xsd:float(?efficency_labels) AS ?efficency_values)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ2296",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Prior hs model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prior hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0082",
            "query_type": "Factoid",
            "question": {
                "string": "What is another name for Bisphenol A?"
            },
            "paraphrased_question": [
                "How is BisphenolA called alternatively?"
            ],
            "query": {
                "sparql": "SELECT ?same_name_label\nWHERE {\n  ?resources rdfs:label ?resources_labels.\n  FILTER(REGEX(?resources_labels, \"Bisphenol A\", \"i\"))\n  ?resources orkgp:SAME_AS ?same_name.\n  ?same_name rdfs:label ?same_name_label.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "HQ0012",
            "query_type": "Factoid",
            "question": {
                "string": "Does \"ZoomRDF\" uses filters?"
            },
            "paraphrased_question": [
                "Does the paper \"paper title\" uses filters?"
            ],
            "query": {
                "sparql": "SELECT ?uses_filter\nWHERE {\n  ?paper orkgp:P5025 ?filter;\n         rdfs:label ?title.\n  FILTER(REGEX(?title, \"ZoomRDF\"))\n  BIND(\n    IF(?filter = \"T\"^^xsd:string, \"Yes\", \"No\")\n    AS ?uses_filter\n  )\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ2340",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the MP-EB model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MP-EB\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0091",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Stanford Cars dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Stanford Cars\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0371",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the CS-NER dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CS-NER\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1363",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the PolyAI Reddit dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PolyAI Reddit\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1051",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1592",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the EBM-NLP benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1026",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the IMDb-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1148",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the COPA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"COPA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0971",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Q*Bert dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Q*Bert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1081",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the TACRED dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TACRED\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1798",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the WOS-5736 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WOS-5736\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0333",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the EBM-NLP benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1344",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the iNaturalist 2019 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"iNaturalist 2019\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0022",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2445",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BiT-S (ResNet-152x4) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-S (ResNet-152x4)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0118",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Quora Question Pairs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Quora Question Pairs\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1581",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Error metric on the DBpedia benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DBpedia\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0428",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the WMT2016 English-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2450",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the XLNet Large Cased model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLNet Large Cased\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2112",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Transformer-XL (24 layers, RMS dynamic eval, decay) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL (24 layers, RMS dynamic eval, decay)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0415",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the CIFAR-100 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0588",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Atlantis dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Atlantis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0440",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Multimodal PISA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Multimodal PISA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1108",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the WMT2016 English-Romanian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-Romanian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2129",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the AWD-LSTM (3 layers) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM (3 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1496",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of BLEU metric on the RotoWire benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2412",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the CAIT-XS-24 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-XS-24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0944",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Enduro dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Enduro\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0471",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the SearchQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SearchQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0028",
            "query_type": "Non-factoid",
            "question": {
                "string": "Which indicators for well-being are used in the studies on the effect of COVID-19?"
            },
            "paraphrased_question": [
                "Which indicators for wellbeing are used in the study \"The effect of the COVID19 pandemic on wellbeing\"?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?indicators, ?indicators_labels\nWHERE {\n  orkgr:R78492 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P36089 ?indicators.\n  ?indicators rdfs:label ?indicators_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1921",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Linformer model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Linformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0083",
            "query_type": "Factoid",
            "question": {
                "string": "What is the amount of questions for LC-QuAD 2.0 dataset?"
            },
            "paraphrased_question": [
                "How many questions does LCQuAD 2.0 dataset contain?"
            ],
            "query": {
                "sparql": "SELECT ?number_of_questions\nWHERE {\n  orkgr:R154290 orkgp:P31 ?contrib.\n  ?contrib orkgp:P41923 ?number_of_questions.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ2119",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Transformer-XL (24 layers) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL (24 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1384",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the DuIE dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DuIE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2330",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Go-Explore model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Go-Explore\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1407",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of RE+ Macro F1 score when benchmarked on the ADE Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE+ Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2192",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Adaptive Input Very Large model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Adaptive Input Very Large\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2028",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CMLM+LAT+1 iterations model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CMLM+LAT+1 iterations\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1326",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the BBCSport dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BBCSport\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1645",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest SUCCESS score on the Habitat 2020 Point Nav test-std benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SUCCESS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0265",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Kangaroo dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Kangaroo\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1303",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Montezuma\\'s Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Montezuma\\'s Revenge\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2166",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Inan et al. (2016) - Variational RHN model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Inan et al. (2016) - Variational RHN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2358",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BiT-L model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-L\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1480",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of ROUGE-2 metric on the CNN / Daily Mail benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-2\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CNN / Daily Mail\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0246",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Berzerk dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Berzerk\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1694",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Medium Human-Normalized Score score on the Atari-57 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari-57\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0593",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 River Raid dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 River Raid\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0524",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SST-2 Binary classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SST-2 Binary classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2396",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the DeiT-S model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DeiT-S\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1658",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy (%) score when benchmarked on the CINIC-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CINIC-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1824",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Macro F1 metric on the NLP-TDMS (Exp, arXiv only) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0065",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What is the maximum egg mass in studies?"
            },
            "paraphrased_question": [
                "What is the highest mass of embroyo eggs mentioned in the studies?"
            ],
            "query": {
                "sparql": "SELECT MAX(?egg_masses_float)\nWHERE {\n  orkgr:R34845 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15692 ?egg_masses.\n  BIND(xsd:float(?egg_masses) AS ?egg_masses_float)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ0016",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the ScienceIE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ScienceIE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0113",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the CoQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0810",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the QuAC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"QuAC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2001",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the multi-head model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"multi-head\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2125",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Transformer-XL (18 layers) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer-XL (18 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0632",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Gravitar dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0997",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0581",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Double Dunk dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Double Dunk\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0228",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Barabasi-Albert dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1957",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SciGEN model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciGEN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1461",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the BioASQ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BioASQ\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1832",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the PROTEINS benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PROTEINS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1050",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset TDMSci?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TDMSci\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0442",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the HMDB51 (finetuned) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1396",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the ACE 2005 dataset in terms of Sentence Encoder metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Sentence Encoder\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2005\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0849",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the  Jacquard dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \" Jacquard dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1525",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Number of params score when benchmarked on the Hutter Prize dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Hutter Prize\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1996",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the SciBERT (SciVocab) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT (SciVocab)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1350",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Flowers-102?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Flowers-102\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0908",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the MLDoc Zero-Shot English-to-Spanish dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Spanish\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1601",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CIFAR-10 dataset in terms of FLOPS metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1948",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DyGIE++ + OpenIE +  Stanford Core NLP PoS tagger enriched by consistent triples model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DyGIE++ + OpenIE +  Stanford Core NLP PoS tagger enriched by consistent triples\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2190",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Neural cache model (size = 100) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Neural cache model (size = 100)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1675",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the MLDoc Zero-Shot English-to-Spanish dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Spanish\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0319",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the ObjectNet (Bounding Box) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ObjectNet (Bounding Box)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1184",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the WikiText-2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WikiText-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0174",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the DCASE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DCASE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1389",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the ACE 2004 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACE 2004\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1902",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Document Classification research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Document Classification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0758",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the CIFAR-100 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2404",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CAIT-M-24 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-M-24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1867",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Language Modelling research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Language Modelling\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1146",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the WebQuestions dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WebQuestions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0860",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the DCASE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DCASE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0771",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the WMT2016 English-German benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0074",
            "query_type": "Factoid/Ranking",
            "question": {
                "string": "For what product minimum conversion was obtained?"
            },
            "paraphrased_question": [
                "What product in the studies is characterized by the lowest value of conversion?"
            ],
            "query": {
                "sparql": "SELECT ?product, ?product_label\nWHERE {\n  orkgr:R155272 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43149 ?product;\n           orkgp:P43148 ?conversion.\n  ?product rdfs:label ?product_label.\n  ?conversion rdfs:label ?conversion_label.\n}\nORDER BY ASC(xsd:float(?conversion_label))\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1218",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the BC5CDR dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0063",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the NYT-single dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT-single\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2366",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the CeiT-T (384 finetune resolution) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-T (384 finetune resolution)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1756",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Star Gunner benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Star Gunner\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1548",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of SICK-E metric on the SentEval benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SICK-E\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1368",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the PROTEINS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PROTEINS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2023",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Unsupervised PBSMT model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Unsupervised PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2019",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the SciIE model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciIE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0719",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Automatically labeled Medline abstracts corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Automatically labeled Medline abstracts corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2108",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the XLNet (Large) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLNet (Large)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1313",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 HERO dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 HERO\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1491",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Recall score when benchmarked on the Rotowire (Content Selection) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Recall\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Rotowire (Content Selection)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0370",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the SciGEN dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciGEN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2402",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CAIT-M-36 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-M-36\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1473",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the TriviaQA dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TriviaQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0054",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the NYT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1669",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the DTD dataset in terms of PARAMS metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DTD\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0464",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Story Cloze Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Story Cloze Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0571",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Barabasi-Albert dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Barabasi-Albert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1695",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Ms. Pacman benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Ms. Pacman\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2242",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the SciBERT (active learning) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT (active learning)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0718",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Annotated development corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Annotated development corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1161",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the RotoWire (Content Ordering) dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RotoWire (Content Ordering)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1941",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the DocTAET-TDM model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DocTAET-TDM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0988",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the HoC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HoC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1914",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the HNEABP (BWNE) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"HNEABP (BWNE)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2424",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DY-MobileNetV2 \u00d70.75 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-MobileNetV2 \u00d70.75\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1474",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of EM score when benchmarked on the TriviaQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TriviaQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0213",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Food-101 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Food-101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1764",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Percentage correct score when benchmarked on the CIFAR-100 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage correct\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0640",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the BBCSport dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BBCSport\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1359",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the BUCC Chinese-to-English dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Chinese-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1524",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Perplexity score when benchmarked on the LAMBADA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"LAMBADA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0867",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the SST-2 Binary classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SST-2 Binary classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0725",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the seel.cse.lsu.edu/data/refsq17.zip dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"seel.cse.lsu.edu/data/refsq17.zip\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2163",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DEQ-TrellisNet model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DEQ-TrellisNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1220",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Finger, spin (DMControl100k)?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1554",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Test mAP score when benchmarked on the AudioSet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Test mAP\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AudioSet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1615",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Reuters-21578 dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters-21578\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1929",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the TokenFuser model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"TokenFuser\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0764",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the IWSLT2014 German-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0198",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Cartpole, swingup (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1909",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the COMET - DynaGen model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"COMET - DynaGen\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2383",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the BiT-L (ResNet) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-L (ResNet)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2187",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the 4 layer QRNN model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"4 layer QRNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1576",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the WSC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WSC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0138",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Winograd Schema Challenge benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Winograd Schema Challenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0972",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Video Pinball dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Video Pinball\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2180",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DEQ-Transformer (medium, adaptive embed) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DEQ-Transformer (medium, adaptive embed)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0767",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the WMT2014 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1362",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset EBM-NLP?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2331",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the RND model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"RND\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0875",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the BC5CDR dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0641",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the IMDb-M dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb-M\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0195",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Finger, spin (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2037",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the SMT + NMT (tuning and joint refinement) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SMT + NMT (tuning and joint refinement)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0817",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the RotoWire (Relation Generation) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire (Relation Generation)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0929",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Breakout dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0695",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the AAN Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AAN Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0848",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Cornell Grasp Dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cornell Grasp Dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0468",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SQuAD2.0 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD2.0 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0925",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari-57 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari-57\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0881",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Finger, spin (DMControl500k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0441",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the UCF101 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1130",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the HMDB51 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1910",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Commonsense Transformers (COMET) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Commonsense Transformers (COMET)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1481",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the QuAC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QuAC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0067",
            "query_type": "Non-factoid",
            "question": {
                "string": "In which papers are energy system scenarios used that consider the 2050 time frame?"
            },
            "paraphrased_question": [
                " Which papers contain evaluation of energy system scenarious usage in the 2050 timeframe?",
                " In which papers are mentioned energy system usage scenarious concerning the 2050 timeframe?"
            ],
            "query": {
                "sparql": "SELECT ?paper\nWHERE {\n  {\n    orkgr:R150337 orkgp:compareContribution ?contrib.\n  } UNION {\n    orkgr:R153801 orkgp:compareContribution ?contrib.\n  }\n  ?paper orkgp:P31 ?contrib.\n  {\n     ?contrib orkgp:P37586 ?scenarios.\n     ?scenarios orkgp:P37675 ?studies.\n     ?studies orkgp:P35205 ?timeframes.\n  } UNION {\n     ?contrib orkgp:P37581 ?scenario.\n     ?scenario orkgp:P43138 ?goal.\n     ?goal orkgp:P43139 ?timeframes.\n  }\n  FILTER(xsd:int(?timeframes) = 2050)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "star",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 8
        },
        {
            "id": "AQ1036",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ACL Anthology dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACL Anthology\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1246",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Reuters RCV1/RCV2 English-to-German?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 English-to-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2099",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the MAC model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MAC\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2326",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Dueling DQN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Dueling DQN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2115",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Sandwich Transformer (adaptive span) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sandwich Transformer (adaptive span)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2327",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Prioritized DQN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prioritized DQN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1124",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Oxford 102 Flowers dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0564",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the MLDoc Zero-Shot German-to-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot German-to-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1805",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the iNaturalist 2019 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"iNaturalist 2019\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0135",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the PIQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PIQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0304",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WOS-46985 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-46985\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1455",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the Natural Questions (short) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Natural Questions (short)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0166",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the OntoNotes dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OntoNotes\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0151",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Hutter Prize dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Hutter Prize\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1232",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Cartpole, swingup (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1005",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ObjectNet (Bounding Box) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ObjectNet (Bounding Box)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1924",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Poolingformer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Poolingformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2257",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the NASNet-A + c/o model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NASNet-A + c/o\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0823",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the ARC (Easy) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1709",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Beam Rider dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Beam Rider\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1224",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Finger, spin (DMControl500k) dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1934",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the GShard model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GShard\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0018",
            "query_type": "Non-factoid",
            "question": {
                "string": "Which methods are used?"
            },
            "paraphrased_question": [
                "What are the methods used?",
                "Which methods are applied?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?methods, ?methods_labels\nWHERE {\n  orkgr:R110361 orkgp:compareContribution ?cont.\n  ?cont orkgp:HAS_METHOD ?methods.\n  ?methods rdfs:label ?methods_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1885",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Word Embeddings research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Word Embeddings\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1068",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the seel.cse.lsu.edu/data/refsq17.zip dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"seel.cse.lsu.edu/data/refsq17.zip\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0089",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the IWSLT2015 English-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2015 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2204",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the FS-LSTM-2 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"FS-LSTM-2\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1032",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the STEM-ECR v1.0 dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STEM-ECR v1.0\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0926",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Ms. Pacman dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Ms. Pacman\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0224",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the MLDoc Zero-Shot English-to-Chinese dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Chinese\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1052",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the SciCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2430",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the OverFeat - 7 accurate models model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"OverFeat - 7 accurate models\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0919",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the AESLC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AESLC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1789",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Best Score score on the Atari 2600 Frostbite benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Best Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0089",
            "query_type": "Factoid",
            "question": {
                "string": "Does FEEM Sustainability Index consider air quality?"
            },
            "paraphrased_question": [
                "Is air quality accounted for in the FEEM Sustainability Index?"
            ],
            "query": {
                "sparql": "ASK {\n  ?papers rdf:type orkgc:Paper.\n  ?papers rdfs:label ?papers_labels.\n  FILTER(REGEX(?papers_labels, \"FEEM Sustainability Index\"))\n  ?papers orkgp:P31 ?contrib.\n  ?contrib ?properties ?properties_values.\n  ?properties rdfs:label ?properties_labels.\n  FILTER(REGEX(?properties_labels, \"air quality\", \"i\"))\n  FILTER(?properties_values = \"yes\")\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "BOOLEAN",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1501",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Winograd Schema Challenge dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Winograd Schema Challenge\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2253",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the NAT-M4 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NAT-M4\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0079",
            "query_type": "Non-factoid",
            "question": {
                "string": "Which energy system modeling papers indicate where to find their simulation software and whether there are associated simulation scenarios mentioned in ORKG?"
            },
            "paraphrased_question": [
                "What are the simulation scenarios and their code of energy simulation papers?"
            ],
            "query": {
                "sparql": "SELECT ?repo ?scenario ?simulation_parameters\nWHERE {\n  ?paper orkgp:P31 ?contrib.\n  ?contrib orkgp:P37586 ?model.\n  ?model orkgp:P39010 ?code.\n  ?code orkgp:P4077 ?repo.\n  OPTIONAL {\n    ?model orkgp:P43146 ?scenario.\n    {\n      SELECT ?scenario ?simulation_parameters\n      WHERE {\n        ?scenario orkgp:P31 ?contrib2.\n        ?contrib2 orkgp:P37586 ?model2.\n        ?model2 orkgp:P37583 ?data.\n        ?data orkgp:HAS_DATASET ?dataset.\n        ?dataset orkgp:P37343 ?type;\n                 orkgp:P4059 ?simulation_parameters.\n        ?type rdfs:label ?label.\n        FILTER(REGEX(?label, \"Technical\"))\n      }\n    }\n  }\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "forest",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1725",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 Private Eye dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0108",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the DROP Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DROP Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0544",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Ball in cup, catch (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0092",
            "query_type": "Factoid",
            "question": {
                "string": "Does ViCoMap support aggregation?"
            },
            "paraphrased_question": [
                "Can ViCoMap aggregate?"
            ],
            "query": {
                "sparql": "SELECT ?has_aggregation_support\nWHERE {\n  ?application rdfs:label \"ViCoMap\"^^xsd:string;\n               orkgp:P5038 ?has_aggregation_support_.\n  BIND(\n    IF(?has_aggregation_support_ = \"T\"^^xsd:string, \"yes\", \"no\")\n    AS ?has_aggregation_support\n  )\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "star",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ2243",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Random Forest model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Random Forest\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0664",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Flowers-102 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Flowers-102\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0488",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the MedNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MedNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0734",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the IMDb benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0031",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the ART/CoreSC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ART/CoreSC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1308",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Road Runner dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Road Runner\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1588",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the SciCite dataset in terms of F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0226",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the MLDoc Zero-Shot English-to-Italian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0358",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Softcite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Softcite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1319",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Robotank dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1325",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Ohsumed dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Ohsumed\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0267",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Wizard of Wor dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Wizard of Wor\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1984",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SpanRel model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpanRel\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0568",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1911",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Neural Network Language Model (NNLM) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Neural Network Language Model (NNLM)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0303",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the WOS-5736 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1790",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Best Score score on the Atari 2600 Space Invaders benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Best Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Space Invaders\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0478",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the PIQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PIQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2183",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the AdvSoft (+ 4 layer QRNN + dynamic eval) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AdvSoft (+ 4 layer QRNN + dynamic eval)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0050",
            "query_type": "Non-Factoid/Count",
            "question": {
                "string": "What is the average installed capacity of all energy sources considered?"
            },
            "paraphrased_question": [
                "What is the mean value of installed capacity for all energy sources in the studies?"
            ],
            "query": {
                "sparql": "SELECT (AVG(?installed_cap_value) AS ?average_installed_cap_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43133 ?installed_capacity.\n  FILTER(REGEX(?energy_sources_labels, \"all sources\"))\n  ?installed_capacity orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?installed_cap_value)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2241",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the SciBERT (full data) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBERT (full data)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2063",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the XLNet (single model) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLNet (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2232",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Multi-Format Contrastive model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Multi-Format Contrastive\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0421",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the IWSLT2014 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1157",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SearchQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SearchQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0258",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Enduro dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Enduro\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1777",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Top-1 Error Rate metric on the FGVC Aircraft benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Error Rate\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FGVC Aircraft\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0684",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Nottingham dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Nottingham\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0104",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the CUB-200-2011 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CUB-200-2011\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0044",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Pubmed dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Pubmed\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2072",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BART Base (with text infilling) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BART Base (with text infilling)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1843",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Leaderboard extraction research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Leaderboard extraction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2139",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Longformer Small model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Longformer Small\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0251",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Amidar dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0389",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the FB15k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"FB15k\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1477",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of EM metric on the SQuAD1.1 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD1.1\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2100",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Hierarchical Transformer Encoder + conditional copy model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Hierarchical Transformer Encoder + conditional copy\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0125",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the SQuAD2.0 dev dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD2.0 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1386",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CoNLL04 dataset in terms of NER Micro F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoNLL04\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2268",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BioSentVec (PubMed + MIMIC-III) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BioSentVec (PubMed + MIMIC-III)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0753",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the NYT24 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT24\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1690",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Name This Game dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Name This Game\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0743",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the CoNLL04 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL04\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0484",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the RTE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RTE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0911",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the MLDoc Zero-Shot English-to-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2435",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BBG (ResNet-18) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BBG (ResNet-18)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2155",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the AWD-LSTM-DOC + Partial Shuffle model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-DOC + Partial Shuffle\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1871",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Semantic Textual Similarity research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Semantic Textual Similarity\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0068",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the DDI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1808",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Error metric on the Kuzushiji-MNIST benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1504",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest SemEval 2015 score on the Supervised: benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SemEval 2015\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Supervised:\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2201",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Grave et al. (2016) - LSTM model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Grave et al. (2016) - LSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0203",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Cartpole, swingup (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1476",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the SQuAD1.1 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD1.1\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1424",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of BLEU score metric on the WMT2016 English-Romanian benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-Romanian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1469",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the Quora Question Pairs benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Quora Question Pairs\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2009",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DocRED-Context-Aware model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DocRED-Context-Aware\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1107",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset IWSLT2014 German-English?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2014 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0760",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the WMT2016 English-Russian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Russian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2317",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Discrete Latent Space World Model (VQ-VAE) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Discrete Latent Space World Model (VQ-VAE)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0796",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Natural Questions dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1970",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the CRF with term expansion model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CRF with term expansion\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1101",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the CIFAR-100 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-100\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1404",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Relation F1 score on the SciERC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Relation F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciERC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0200",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Cart Pole (OpenAI Gym) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cart Pole (OpenAI Gym)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1540",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Text8 dataset in terms of Bit per Character (BPC) metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bit per Character (BPC)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2279",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the PtGen model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PtGen\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0624",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Boxing dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Boxing\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0077",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WMT2016 English-Czech dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Czech\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0093",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Fashion-MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Fashion-MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2138",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Longformer Large model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Longformer Large\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0239",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari-57 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari-57\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1560",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Yelp Fine-grained classification dataset in terms of Error metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp Fine-grained classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1536",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the WikiText-2 dataset in terms of Validation perplexity metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Validation perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WikiText-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0951",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 Kangaroo dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Kangaroo\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0130",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Rotowire (Content Selection) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Rotowire (Content Selection)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2154",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the AWD-LSTM + dynamic eval model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM + dynamic eval\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1823",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the PWC Leaderboards (restricted) dataset in terms of Micro Recall metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro Recall\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PWC Leaderboards (restricted)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0672",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the BUCC French-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC French-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1150",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Story Cloze Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Story Cloze Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0052",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the TACRED dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TACRED\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0966",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Phoenix dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2031",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BiGRU model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiGRU\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2114",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Feedback Transformer model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Feedback Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0761",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the WMT2014 English-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1444",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the HMDB51 (finetuned) dataset in terms of Top-1 Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1198",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the SentEval dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2440",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the KNN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"KNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0755",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the CoLA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoLA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1935",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Scaling Transformers model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Scaling Transformers\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0254",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Krull dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1099",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the AG News dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AG News\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1879",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the PointGoal Navigation research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"PointGoal Navigation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1506",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Senseval 3 metric on the Supervised: benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Senseval 3\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Supervised:\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0809",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the CNN / Daily Mail dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CNN / Daily Mail\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1365",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the NLP-TDMS (Exp, arXiv only) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1299",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Yars Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Yars Revenge\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2442",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DAT model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DAT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0814",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the SearchQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SearchQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1677",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the MLDoc Zero-Shot English-to-Chinese dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Chinese\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0289",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Atari 2600 Gravitar benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gravitar\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0155",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the WikiText-2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WikiText-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1606",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Stanford Cars dataset in terms of Accuracy (%) metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Stanford Cars\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1623",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of 5 fold cross validation metric on the Cornell Grasp Dataset benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"5 fold cross validation\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cornell Grasp Dataset\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1420",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of BLEU score score when benchmarked on the WMT2014 French-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1306",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Bowling dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Bowling\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2406",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CAIT-S-48 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-S-48\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0527",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the BC2GM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC2GM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0337",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the MUTAG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MUTAG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1998",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SpERT model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SpERT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1028",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Open Entity dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Open Entity\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1585",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the HoC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HoC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0750",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the SciERC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciERC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1944",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the D-NLI model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"D-NLI\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0271",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Ice Hockey dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Ice Hockey\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0412",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the CoLA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoLA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0360",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the OA-STM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1490",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Precision metric on the Rotowire (Content Selection) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Precision\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Rotowire (Content Selection)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1960",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Classifier Chain + SMO model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Classifier Chain + SMO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1441",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Multimodal PISA dataset in terms of Accuracy (%) metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Multimodal PISA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0185",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the CoNLL++ benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL++\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0270",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Yars Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Yars Revenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0748",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the SemEval-2010 Task 8 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2010 Task 8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1187",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Text8?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Text8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0069",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the CoLA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoLA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1708",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Krull benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0633",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Robotank dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0081",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the WMT2014 German-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2136",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Compressive Transformer model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Compressive Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0199",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Cheetah, run (DMControl100k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2271",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the LSTM Encoder-Decoder + LSTM-LM model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LSTM Encoder-Decoder + LSTM-LM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2284",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Concept pointer+DS model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Concept pointer+DS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0514",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the GENIA - UAS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - UAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1666",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of FLOPS score when benchmarked on the CIFAR-10 Image Classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10 Image Classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0390",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Twitter dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Twitter\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1304",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Frostbite dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Frostbite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0449",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Quasart-T dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Quasart-T\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0722",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the NLP-TDMS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NLP-TDMS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2346",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DQN+SR model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DQN+SR\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0472",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the One Billion Word dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"One Billion Word\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0587",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Centipede dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Centipede\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1018",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the ModelNet40 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ModelNet40\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1681",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of ROUGE-1 metric on the arXiv benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"arXiv\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2098",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the GPT-3 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GPT-3\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "HQ0066",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "What is the most common substrate for catalysts?"
            },
            "paraphrased_question": [
                "Which substrate is most commonly used as a catalyst in the papers?"
            ],
            "query": {
                "sparql": "SELECT ?substrate\nWHERE {\n  orkgr:R25900 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15090 ?substrate.\n}\nORDER BY DESC(COUNT(?substrate))\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ0017",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the OA-STM benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OA-STM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0563",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MLDoc Zero-Shot English-to-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0811",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the SQuAD2.0 dev benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SQuAD2.0 dev\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0045",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Amazon dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Amazon\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2086",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the MEMEN (ensemble) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MEMEN (ensemble)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0606",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Time Pilot dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Time Pilot\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1178",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the enwik8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwik8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0736",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Amazon-5 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Amazon-5\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1727",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Battle Zone benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Battle Zone\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0782",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Kinetics-600 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Kinetics-600\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0486",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the CommitmentBank dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommitmentBank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0219",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the MLDoc Zero-Shot English-to-Japanese benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Japanese\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0990",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the WOS-46985 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-46985\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0047",
            "query_type": "Factoid/Count",
            "question": {
                "string": "What is the average reproductive number for studies?"
            },
            "paraphrased_question": [
                "What is the mean basic reproductive number in the COVID studies?"
            ],
            "query": {
                "sparql": "SELECT (AVG(?reproductive_number) AS ?average_reproductive_number)\nWHERE {\n  orkgr:R44930 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P23140 ?basic_reproductive_number.\n  ?basic_reproductive_number orkgp:HAS_VALUE ?value\n  BIND(xsd:float(?value) AS ?reproductive_number)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain\n",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0408",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the ADE Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0619",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Private Eye dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1453",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy (%) score on the Hendrycks Test benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Hendrycks Test\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1676",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the MLDoc Zero-Shot English-to-Russian benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Russian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0869",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the BC5CDR-chemical benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-chemical\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1309",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Phoenix dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0613",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Yars Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Yars Revenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1204",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ESC-50 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ESC-50\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0708",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0905",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the MLDoc Zero-Shot English-to-Japanese benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Japanese\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1697",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 Breakout dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0324",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Birdsnap dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Birdsnap\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1120",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Stanford Cars dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Stanford Cars\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1519",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the WNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1841",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Open link prediction research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Open link prediction\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0020",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the ner_dataset_recognition dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ner_dataset_recognition\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2206",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the 2-layer Norm HyperLSTM model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"2-layer Norm HyperLSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1855",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Machine Translation research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Machine Translation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0521",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Yelp Fine-grained classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp Fine-grained classification\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1717",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Kangaroo benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Kangaroo\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0945",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Solaris dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0476",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the RotoWire dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0294",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Yelp-5 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-5\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1195",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset OntoNotes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"OntoNotes\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1020",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the PolyAI Reddit dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PolyAI Reddit\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0494",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Hutter Prize dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Hutter Prize\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1270",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Pitfall! dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Pitfall!\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0784",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the UCF101 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"UCF101\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2121",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Sparse Transformer (30 layers, fixed attn) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sparse Transformer (30 layers, fixed attn)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0162",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Cornell Grasp Dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cornell Grasp Dataset\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1574",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest nDCG@20 score on the ClueWeb09-B benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"nDCG@20\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ClueWeb09-B\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0349",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the ARC-PDN dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC-PDN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0369",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the SciTLDR dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciTLDR\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2261",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the MultiCCA + CNN model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MultiCCA + CNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1792",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Best Score score on the Atari 2600 Q*Bert benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Best Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Q*Bert\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1770",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the STL-10 dataset in terms of Percentage correct metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Percentage correct\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STL-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0501",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Text8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Text8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2110",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the ESIM + ELMo Ensemble model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ESIM + ELMo Ensemble\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0883",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Lunar Lander (OpenAI Gym) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Lunar Lander (OpenAI Gym)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0768",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the WMT2016 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2189",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Neural cache model (size = 2,000) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Neural cache model (size = 2,000)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0601",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Enduro dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Enduro\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0115",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the CommonsenseQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0665",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the iNaturalist 2018 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"iNaturalist 2018\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0095",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Oxford 102 Flowers dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2250",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the RGBD+DD-PPO model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"RGBD+DD-PPO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0614",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Ice Hockey dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Ice Hockey\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0341",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Nottingham dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Nottingham\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0909",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the MLDoc Zero-Shot English-to-Russian benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Russian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1919",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Performer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Performer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1298",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Defender?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Defender\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0202",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Cheetah, run (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0889",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Cartpole, swingup (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cartpole, swingup (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0186",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the CoNLL 2003 (English) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2003 (English)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0071",
            "query_type": "Non-factoid",
            "question": {
                "string": "What are areas of study?"
            },
            "paraphrased_question": [
                "What locations are studied?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?areas, ?areas_labels\nWHERE {\n  orkgr:R155445 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P37041 ?areas.\n  ?areas rdfs:label ?areas_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0589",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Berzerk dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Berzerk\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1883",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Constituency Parsing research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Constituency Parsing\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0016",
            "query_type": "Factoid/",
            "question": {
                "string": "What is major reactant for \"Microwave-Assisted Cobinamide Synthesis\"?"
            },
            "paraphrased_question": [
                "What is the major reactant of paper \"paper title\"?"
            ],
            "query": {
                "sparql": "SELECT ?reactant\nWHERE {\n  ?papers rdfs:label ?titles.\n  FILTER(REGEX(?titles, \"Microwave-Assisted Cobinamide Synthesis\"))\n  ?papers orkgp:P31 ?cont.\n  ?cont orkgp:P37557 ?reactant.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0481",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Winograd Schema Challenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Winograd Schema Challenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2109",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the NCBI_BERT(base) (P+M) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NCBI_BERT(base) (P+M)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1265",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Atari 2600 Gopher dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0074",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the WMT2016 English-Russian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Russian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1109",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the 20NEWS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"20NEWS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2000",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Relation-Metric with AT model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Relation-Metric with AT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1284",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Beam Rider dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Beam Rider\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0649",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Yelp-14 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-14\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2147",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the FS-LSTM-4 model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"FS-LSTM-4\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2185",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the DEQ-Transformer (small) model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DEQ-Transformer (small)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1382",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 score when benchmarked on the JNLPBA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"JNLPBA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0673",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the BUCC Chinese-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC Chinese-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1596",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest MRR score on the FB15k benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"MRR\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FB15k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1331",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the HoC dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HoC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2421",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CeiT-T (384 finetune res) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CeiT-T (384 finetune res)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2388",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the EfficientNetV2-S model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EfficientNetV2-S\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0694",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Scholarly entity usage detection benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Scholarly entity usage detection\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2254",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the NAT-M3 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NAT-M3\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2011",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SciBert (Finetune) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SciBert (Finetune)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1881",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of benchmarked datasets related to the Neural Architecture Search research area?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Neural Architecture Search\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0317",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Kuzushiji-MNIST benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1341",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ScienceCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ScienceCite\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0840",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the The Pile dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"The Pile\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0296",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Ohsumed dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Ohsumed\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0032",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Annotated development corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Annotated development corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1486",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of EM score when benchmarked on the SQuAD2.0 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SQuAD2.0\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1078",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Penn Treebank dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0205",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Habitat 2020 Point Nav test-std dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0902",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the AAPD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"AAPD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1736",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the BBCSport benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BBCSport\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0680",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the MUTAG dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MUTAG\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1209",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Yelp Binary classification dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp Binary classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2227",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the PAR BERT Base model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PAR BERT Base\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2276",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BertSumExtAbs model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BertSumExtAbs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1546",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Pearson Correlation score on the STS Benchmark benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Pearson Correlation\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"STS Benchmark\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0053",
            "query_type": "Non-factoid/Ranking",
            "question": {
                "string": "What is the minimum and maximum energy generation for each energy source considered?"
            },
            "paraphrased_question": [
                " What are the boundaries of energy production capacities for each energy source?",
                " In what interval lie the power output capabilities of every considered energy source installment type?"
            ],
            "query": {
                "sparql": "SELECT ?energy_sources_labels (MIN(?elec_gen_value) AS ?min_elec_gen_value) (MAX(?elec_gen_value) AS ?max_elec_gen_value)\nWHERE {\n  orkgr:R153801 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P43135 ?energy_sources.\n  ?energy_sources rdfs:label ?energy_sources_labels;\n                  orkgp:P43134 ?elec_gen.\n  ?elec_gen orkgp:HAS_VALUE ?value.\n  BIND(xsd:float(?value) AS ?elec_gen_value)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0312",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the ScienceCite dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ScienceCite\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1336",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Reuters En-De dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters En-De\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1775",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Top 5 Accuracy metric on the ImageNet benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 5 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0791",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Hendrycks Test dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Hendrycks Test\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0781",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Oxford 102 Flowers dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2320",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Reactor 500M model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Reactor 500M\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2229",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BiLSTM-CRF model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-CRF\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0090",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Stanford Dogs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Stanford Dogs\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0842",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the enwiki8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"enwiki8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1632",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Finger, spin (DMControl500k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2338",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Sarsa-\u03b5 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sarsa-\u03b5\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1172",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset CommitmentBank?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CommitmentBank\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0490",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the WNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2018",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DyGIE++ model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DyGIE++\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2352",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the HDLTex model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"HDLTex\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0660",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Kuzushiji-MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Kuzushiji-MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2174",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Feedback Transformer (8 layers) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Feedback Transformer (8 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0773",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the WMT2016 Czech-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 Czech-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2055",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the XLNet model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"XLNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1651",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Medium Human-Normalized Score score when benchmarked on the Dmlab-30 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Medium Human-Normalized Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0681",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the REDDIT-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"REDDIT-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0707",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the TDMSci dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TDMSci\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1744",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score score on the BUCC French-to-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC French-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1104",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the WMT2014 English-French dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0096",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "Who is the author with the largest number of papers about semantic representation in music research problem? "
            },
            "paraphrased_question": [
                "Who has the most contributions to semantic representation in the music research problem?"
            ],
            "query": {
                "sparql": "SELECT ?author\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers orkgp:P31 ?contrib.\n  ?contrib orkgp:P32 ?research_problems.\n  ?research_problems rdfs:label ?research_problems_labels.\n  FILTER(REGEX(?research_problems_labels, \"semantic representation in music\", \"i\"))\n  ?papers orkgp:P27 ?authors.\n  OPTIONAL {\n    ?authors rdfs:label ?authors_labels\n  }\n  BIND(IF(BOUND(?authors_labels), ?authors_labels, ?authors) AS ?author)\n}\nORDER BY DESC(COUNT(?author))\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHAT-WHO",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0305",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Reuters De-En dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters De-En\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2096",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the LUKE (single model) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LUKE (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1352",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset ObjectNet?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ObjectNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1188",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the MedSTS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MedSTS\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2177",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Transformer (Adaptive inputs) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (Adaptive inputs)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2016",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Relation-Metric model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Relation-Metric\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2456",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the MMDL model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MMDL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1648",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of SPL metric on the Habitat 2020 Object Nav test-std benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SPL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0548",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Habitat 2020 Point Nav test-std dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Habitat 2020 Point Nav test-std\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1040",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ORKG-TDM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0697",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the ORKG-TDM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ORKG-TDM\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2042",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Sparse Transformer 59M (strided) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Sparse Transformer 59M (strided)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2024",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Unsupervised NMT + Transformer model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Unsupervised NMT + Transformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0143",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the CommitmentBank dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommitmentBank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0280",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Phoenix dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1041",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the TDM Tagged Corpus dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"TDM Tagged Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1228",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Cheetah, run (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0391",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the IMDb dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2126",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Transformer (64 layers) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (64 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0297",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the BBCSport benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BBCSport\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1507",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the Words in Context dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Words in Context\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0936",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Atari 2600 River Raid dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 River Raid\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2012",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the NCBI_BERT(large) (P) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NCBI_BERT(large) (P)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0968",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Space Invaders dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Space Invaders\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0989",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the WOS-5736 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WOS-5736\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0851",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the DDI extraction 2013 corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI extraction 2013 corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0560",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Reuters RCV1/RCV2 English-to-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1445",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest 3-fold Accuracy score on the UCF101 (finetuned) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"3-fold Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1043",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the SoMeSci dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SoMeSci\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0598",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Beam Rider dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Beam Rider\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1468",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the WebQuestions dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WebQuestions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1527",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Params metric on the Penn Treebank (Word Level) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0316",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the ImageNet V2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet V2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1679",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the MLDoc Zero-Shot English-to-Italian dataset in terms of Accuracy metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Italian\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2313",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Prior+Duel hs model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Prior+Duel hs\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1968",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the BiLSTM-Attn w/ ELMo + section title and citation worthiness scaffolds model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiLSTM-Attn w/ ELMo + section title and citation worthiness scaffolds\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2288",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Struct+2Way+Word model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Struct+2Way+Word\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1629",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Ball in cup, catch (DMControl500k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Ball in cup, catch (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1782",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Top 1 Accuracy score when benchmarked on the Food-101 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top 1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Food-101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0836",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the LAMBADA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"LAMBADA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1132",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the RACE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RACE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1728",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Atari 2600 Road Runner dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Road Runner\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1129",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset UCF101 (finetuned)?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"UCF101 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2236",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the SB-CNN noaug model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SB-CNN noaug\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0325",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the STL-10, 1000 Labels dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STL-10, 1000 Labels\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1454",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of EM metric on the Quasart-T benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"EM\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Quasart-T\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0491",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the QNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"QNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1247",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Reuters RCV1/RCV2 German-to-English?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters RCV1/RCV2 German-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1291",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Skiing dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Skiing\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1995",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BiTT model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiTT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2343",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the RUDDER model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"RUDDER\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0993",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Reuters En-De dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Reuters En-De\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1431",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the IWSLT2015 German-English dataset in terms of BLEU score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"IWSLT2015 German-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0898",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the CINIC-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0590",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Zaxxon dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Zaxxon\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0269",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Atari 2600 Defender benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Defender\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2291",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BertSumExt model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BertSumExt\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2075",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the S-Norm model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"S-Norm\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0417",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the WMT2016 English-Russian dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 English-Russian\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1705",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Score score on the Atari 2600 Amidar benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Amidar\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1570",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the BC5CDR-disease dataset in terms of F1 entity level metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 entity level\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1628",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Score score when benchmarked on the Finger, spin (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl100k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2133",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Hypernetworks model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Hypernetworks\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1276",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Zaxxon dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Zaxxon\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0741",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the JNLPBA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"JNLPBA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2065",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the FusionNet model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"FusionNet\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0385",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1986",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Naive Bayes model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Naive Bayes\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0847",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ImageNet\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0947",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Atari 2600 Venture dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2039",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the GPT-3 175B (Few-Shot) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GPT-3 175B (Few-Shot)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1347",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the ImageNet ReaL dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet ReaL\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2415",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the CvT-21 model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-21\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1054",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset SciFACT?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SciFACT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0828",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the MultiNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MultiNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2407",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the DeiT-B 384 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DeiT-B 384\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0663",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SVHN dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1950",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the BERT-based binary sentence classifier model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BERT-based binary sentence classifier\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2289",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Contextual Match model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Contextual Match\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2222",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the GGCNN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GGCNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1961",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the LibSVM model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LibSVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0076",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the WMT2014 French-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 French-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0098",
            "query_type": "Factoid",
            "question": {
                "string": "Does OWLMAP imply integrity constraints?"
            },
            "paraphrased_question": [
                "Are integrity constraints involved in OWLMAP?"
            ],
            "query": {
                "sparql": "ASK {\n  ?approach rdfs:label \"OWLMAP\"^^xsd:string.\n  ?contrib ?predicate ?approach.\n  ?contrib orkgp:P41333 ?integrity_constraints.\n  FILTER(?integrity_constraints = \"t\"^^xsd:string)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "BOOLEAN",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1699",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Atari 2600 Atlantis dataset in terms of Score metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Atlantis\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2393",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CvT-W24 (384 res, ImageNet-22k pretrain) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CvT-W24 (384 res, ImageNet-22k pretrain)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2004",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the SPTree model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SPTree\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1015",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the BUCC French-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC French-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1421",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of BLEU score metric on the WMT2016 English-Czech benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 English-Czech\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0844",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Text8 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Text8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0676",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the EBM-NLP dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"EBM-NLP\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0330",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the BUCC Chinese-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BUCC Chinese-to-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0215",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the DTD benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DTD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2105",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the QA-GNN model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"QA-GNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0658",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the iNaturalist 2019 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"iNaturalist 2019\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0683",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the IMDb-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1647",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of SOFT_SPL metric on the Habitat 2020 Object Nav test-std benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SOFT_SPL\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Habitat 2020 Object Nav test-std\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2123",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the All-attention network (18 layers) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"All-attention network (18 layers)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2314",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the ES FF (1 hour) noop model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ES FF (1 hour) noop\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0187",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the BC5CDR-disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BC5CDR-disease\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1856",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Unsupervised Machine Translation research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Unsupervised Machine Translation\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1301",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Tutankham?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Tutankham\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0076",
            "query_type": "Non-factoid",
            "question": {
                "string": "What preprocessing methods are used?"
            },
            "paraphrased_question": [
                "What is the list of preprocessing methods involved in the studies?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?prep_methods, ?prep_methods_labels\nWHERE {\n  orkgr:R155154 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P41006 ?prep_methods.\n  ?prep_methods rdfs:label ?prep_methods_labels.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1199",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the MRPC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MRPC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0372",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the CORLL dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1955",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CATTS model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CATTS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0906",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the MLDoc Zero-Shot English-to-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2357",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the ViT-H/14 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ViT-H/14\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1063",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Abstracts\\' entities and relations annotated corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Abstracts\\' entities and relations annotated corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2150",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the adversarial + AWD-LSTM-MoS + dynamic eval model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"adversarial + AWD-LSTM-MoS + dynamic eval\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0359",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ScienceIE dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ScienceIE\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1549",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest SICK-R score on the SentEval benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"SICK-R\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SentEval\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1661",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy (%) score on the Food-101 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Food-101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1936",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the GLaM model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"GLaM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1181",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Penn Treebank (Word Level)?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0552",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the ClueWeb09-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ClueWeb09-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1377",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Error score on the Amazon-5 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Amazon-5\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2400",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the EfficientNetV2-L (21k) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"EfficientNetV2-L (21k)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0043",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the nuScenes dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"nuScenes\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2433",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the BBG (ResNet-34) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BBG (ResNet-34)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1179",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the LAMBADA dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"LAMBADA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1381",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest F1 score on the NYT benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NYT\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0469",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Natural Questions (long) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions (long)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0045",
            "query_type": "Factoid/Superlative",
            "question": {
                "string": "In what country was conducted research with the largest number of participants?"
            },
            "paraphrased_question": [
                "Where was conducted research with the largest number of participants about the methodological implications of psychodrama psychotherapy?"
            ],
            "query": {
                "sparql": "SELECT ?country\nWHERE {\n  orkgr:R44980 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15249 ?country;\n           orkgp:P23169 ?number_of_participants.\n}\nORDER BY DESC(?number_of_participants)\nLIMIT 1"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ2422",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the DY-MobileNetV2 \u00d71.0 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-MobileNetV2 \u00d71.0\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0513",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the MRPC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MRPC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1237",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Dmlab-30 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Dmlab-30\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1835",
            "query_type": "Factoid",
            "question": {
                "string": "What are the most commonly used benchmark datasets for the Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification. research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Finding an efficient and state-of-the-art approach to search for optimal architectures for image classification.\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2006",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the DYGIE++ model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DYGIE++\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0885",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the Cheetah, run (DMControl100k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0082",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the WMT2016 German-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2016 German-English\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1225",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the Reacher, easy (DMControl500k) dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reacher, easy (DMControl500k)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0165",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the DDI extraction 2013 corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DDI extraction 2013 corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2082",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the MEMEN  (single model) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"MEMEN  (single model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1012",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Sequential MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Sequential MNIST\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0023",
            "query_type": "Non-Factoid",
            "question": {
                "string": "what are the evidence and limitations of paper \"Evaluating the Use of Social Networks in Author Name Disambiguation in Digital Libraries\"?"
            },
            "paraphrased_question": [
                "What are constraints of the findings from paper \"Evaluating the Use of Social Networks in Author Name Disambiguation in Digital Libraries\" and where do they come from?"
            ],
            "query": {
                "sparql": "SELECT ?evidence ?evidence_title ?limitation\nWHERE {\n  orkgr:R6751 orkgp:compareContribution ?cont.\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?paper_title.\n  ?cont orkgp:P5004 ?evidence;\n        orkgp:P5006 ?limitation.\n  ?evidence rdfs:label ?evidence_title.\n  FILTER(REGEX(STR(?paper_title), \"Evaluating the Use of Social Networks in Author Name Disambiguation in Digital Libraries\", \"i\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1025",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the PROTEINS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PROTEINS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0558",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the DTD dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DTD\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0825",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Supervised: benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Supervised:\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1434",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest BLEU score score on the WMT2016 Russian-English benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2016 Russian-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1688",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest ROUGE-2 score on the AESLC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-2\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"AESLC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1411",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Micro F1 score when benchmarked on the DDI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"DDI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0960",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Montezuma\\'s Revenge dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Montezuma\\'s Revenge\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0255",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Beam Rider dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Beam Rider\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0021",
            "query_type": "Factoid",
            "question": {
                "string": "What is the base URL of \"The Document Components Ontology\"?"
            },
            "paraphrased_question": [
                "What is the IRI of \"resource\"?"
            ],
            "query": {
                "sparql": "SELECT ?iri\nWHERE {\n  orkgr:R8342 orkgp:compareContribution ?cont.\n  ?cont orkgp:P7034 ?ont.\n  ?ont orkgp:P7042 ?iri;\n       orkgp:P7035 ?full_name.\n  FILTER(REGEX(STR(?full_name), \"Document Components Ontology\", \"i\"))\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0592",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Demon Attack dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Demon Attack\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1166",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the ARC (Easy) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ARC (Easy)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1534",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the WikiText-2 dataset in terms of Number of params metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Number of params\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WikiText-2\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1219",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the ShARe/CLEF eHealth corpus dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ShARe/CLEF eHealth corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0630",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Chopper Command dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Chopper Command\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0340",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the IMDb-B dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"IMDb-B\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0088",
            "query_type": "Factoid",
            "question": {
                "string": "Who are the authors of the SOSA ontology?"
            },
            "paraphrased_question": [
                "Who were the editors of the Semantic Sensor Network (SOSA) ontology?"
            ],
            "query": {
                "sparql": "SELECT ?authors\nWHERE {\n  ?papers rdf:type orkgc:Paper.\n  ?papers rdfs:label ?papers_labels.\n  FILTER(REGEX(?papers_labels, \"^SOSA\"))\n  ?papers orkgp:P27 ?authors.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "star",
            "query_class": "WHAT-WHO",
            "number_of_patterns": 3
        },
        {
            "id": "AQ0147",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the WNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0292",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the DBpedia dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DBpedia\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0545",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Cheetah, run (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Cheetah, run (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1691",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Gopher benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1868",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Robotic Grasping research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Robotic Grasping\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0461",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Quora Question Pairs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Quora Question Pairs\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2235",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the SB-CNN aug model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SB-CNN aug\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0236",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Atari 2600 Gopher dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Gopher\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "HQ0009",
            "query_type": "Factoid",
            "question": {
                "string": "What is the precision and recall of SemGraphQA?"
            },
            "paraphrased_question": [
                "What is the precision and recall of paper \"paper title\"?",
                "How well does the SemGraphQA perform?",
                "How well is the precision and recall of SemGraphQA?"
            ],
            "query": {
                "sparql": "SELECT ?precision ?recall\nWHERE {\n  orkgr:R6898 orkgp:compareContribution ?cont. \n  ?cont orkgp:P34 ?eval.\n  ?eval rdfs:label ?eval_labels.\n  FILTER(REGEX(?eval_labels, \"SemGraphQA\"))\n  ?eval orkgp:P3004 ?precision;\n        orkgp:P5015 ?recall.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0406",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the NYT-single dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT-single\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1872",
            "query_type": "Factoid",
            "question": {
                "string": "Name the datasets that have been used for benchmarking in the Paraphrase Identification research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Paraphrase Identification\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1741",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Unpermuted Accuracy score when benchmarked on the Sequential MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Unpermuted Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Sequential MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1281",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Atari 2600 Asteroids?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Asteroids\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0007",
            "query_type": "Non-factoid",
            "question": {
                "string": "Which papers use the dataset DBLP?"
            },
            "paraphrased_question": [
                "Which papers analyze DBLP as a dataset?"
            ],
            "query": {
                "sparql": "SELECT DISTINCT ?title\nWHERE {\n ?paper a orkgc:Paper;\n orkgp:P31 [\n   orkgp:P2005 [\n     rdfs:label \"DBLP\"^^xsd:string\n   ]\n ];\n rdfs:label ?title.\n}\nORDER BY ?title"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1614",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of PARAMS score when benchmarked on the Oxford 102 Flowers dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1657",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Oxford-IIIT Pets dataset in terms of PARAMS metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0479",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the OpenBookQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OpenBookQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1408",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the ADE Corpus dataset in terms of RE Macro F1 metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RE Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0146",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the SNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1762",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the Twitter benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Twitter\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1763",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest PARAMS score on the CIFAR-10 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"PARAMS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1737",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the Flowers-102 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Flowers-102\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1448",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the RACE benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RACE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0591",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Assault dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Assault\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0475",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the RotoWire (Content Ordering) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"RotoWire (Content Ordering)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0067",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the NYT24 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT24\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0597",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Krull dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Krull\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2103",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Hierarchical Transformer Encoder +  conditional copy model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Hierarchical Transformer Encoder +  conditional copy\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1217",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the NCBI Disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NCBI Disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1412",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy score on the CoLA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoLA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2131",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Large FS-LSTM-4 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Large FS-LSTM-4\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2272",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the DeepGG model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DeepGG\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0006",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the ARC-PDN dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC-PDN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0321",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Flowers-102 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Flowers-102\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0154",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the The Pile dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"The Pile\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1131",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Reuters-21578 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Reuters-21578\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0356",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the CommonsenseQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CommonsenseQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2280",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Seq2Seq model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Seq2Seq\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0322",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the iNaturalist 2018 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"iNaturalist 2018\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0167",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the CoNLL 2012 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2012\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2137",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the 24-layer Transformer-XL model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"24-layer Transformer-XL\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2359",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the ViT-L/16 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ViT-L/16\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0433",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Stanford Dogs dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Stanford Dogs\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1282",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Kung-Fu Master dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Kung-Fu Master\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0426",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the WMT2014 English-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WMT2014 English-German\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1563",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 score when benchmarked on the NCBI-disease dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NCBI-disease\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0204",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Walker, walk (DMControl500k) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl500k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1516",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of % Test Accuracy metric on the SNLI benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"% Test Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SNLI\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1249",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the MLDoc Zero-Shot English-to-German dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0124",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the QuAC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"QuAC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2102",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Encoder-decoder + conditional copy model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Encoder-decoder + conditional copy\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1165",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the highest benchmark result achieved on the OpenBookQA dataset, including the metric and its value?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"OpenBookQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0626",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 James Bond dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 James Bond\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0879",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Walker, walk (DMControl100k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Walker, walk (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1206",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset SST-5 Fine-grained classification?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"SST-5 Fine-grained classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0609",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Up and Down dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Up and Down\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0907",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the MLDoc Zero-Shot German-to-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot German-to-French\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0923",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Crazy Climber dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Crazy Climber\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2021",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Attentional encoder-decoder + BPE model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Attentional encoder-decoder + BPE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1071",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the MNIST dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MNIST\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1589",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of F1 metric on the ACL-ARC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0463",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the TriviaQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TriviaQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2132",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the LN HM-LSTM model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"LN HM-LSTM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1620",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Top-1 Error Rate score when benchmarked on the ImageNet dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Error Rate\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1829",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Micro Recall score when benchmarked on the NLP-TDMS (Exp, arXiv only) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Micro Recall\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"NLP-TDMS (Exp, arXiv only)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1242",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset Food-101?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Food-101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0853",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the CoNLL 2012 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2012\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1566",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of F1 entity level score when benchmarked on the BC2GM dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"F1 entity level\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BC2GM\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1143",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset BoolQ?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BoolQ\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0243",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Atari 2600 Breakout benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Breakout\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0509",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the OntoNotes dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"OntoNotes\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0175",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the ESC-50 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ESC-50\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0623",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Phoenix dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Phoenix\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1153",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset QuAC?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"QuAC\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1662",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of FLOPS metric on the Food-101 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"FLOPS\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Food-101\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0306",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Yelp-14 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-14\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0311",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the ACL-ARC dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ACL-ARC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0110",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Natural Questions benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Natural Questions\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1406",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of NER Macro F1 metric on the ADE Corpus benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"NER Macro F1\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ADE Corpus\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1290",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the Atari 2600 Venture dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Venture\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1182",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the WikiText-103 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WikiText-103\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0152",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Penn Treebank (Word Level) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1008",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the iNaturalist 2018 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"iNaturalist 2018\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0821",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the PIQA benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"PIQA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0134",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the ARC (Challenge) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ARC (Challenge)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2347",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Qbert Rainbow+SEER model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Qbert Rainbow+SEER\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0234",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Seaquest dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Seaquest\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0979",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Yelp-2 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-2\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0518",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the ESC-50 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"ESC-50\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0106",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Quasart-T dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Quasart-T\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0378",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the DRI Corpus dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"DRI Corpus\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1809",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the ImageNet ReaL benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"ImageNet ReaL\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2374",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the VGG8B(2x) + LocalLearning + CO model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"VGG8B(2x) + LocalLearning + CO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2408",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the CAIT-S-24 model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CAIT-S-24\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0962",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Private Eye benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Private Eye\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0583",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Ms. Pacman dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Ms. Pacman\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2118",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the Transformer (24 layers, 8k adaptive span) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (24 layers, 8k adaptive span)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2093",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the OTF spelling (single) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"OTF spelling (single)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0211",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the Oxford-IIIT Pets dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Oxford-IIIT Pets\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1786",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Score metric on the Atari 2600 Solaris benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Score\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Solaris\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1542",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Pearson Correlation metric on the BIOSSES benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Pearson Correlation\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BIOSSES\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1307",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Atari 2600 Battle Zone dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Atari 2600 Battle Zone\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1926",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Clusterformer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Clusterformer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1429",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of BLEU metric on the WMT2014 English-German benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-German\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0599",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Freeway dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Freeway\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1771",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Accuracy score when benchmarked on the Oxford 102 Flowers dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Oxford 102 Flowers\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0112",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the MultiRC benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MultiRC\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0094",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the STL-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"STL-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0562",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the MLDoc Zero-Shot English-to-Japanese dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"MLDoc Zero-Shot English-to-Japanese\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0260",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the models that have been evaluated on the Atari 2600 Fishing Derby dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1981",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the RNN model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"RNN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1451",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of RACE-h metric on the RACE benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"RACE-h\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"RACE\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0029",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the CORLL dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CORLL\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0620",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the Atari 2600 Bowling dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Bowling\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0368",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the SciFACT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SciFACT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0740",
            "query_type": "Factoid",
            "question": {
                "string": "What evaluation metrics are commonly used when benchmarking models on the NYT dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NYT\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0466",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the CNN / Daily Mail dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CNN / Daily Mail\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2465",
            "query_type": "Factoid",
            "question": {
                "string": "What research problems have benchmarked datasets under the Machine Learning research field?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?problem ?problem_lbl\nWHERE {\n  ?rf       a            orkgc:ResearchField;\n            rdfs:label   ?rf_label.\n  FILTER (str(?rf_label) = \"Machine Learning\")\n  ?paper    orkgp:P30    ?rf;\n            orkgp:P31    ?cont.\n  ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                orkgp:P32                ?problem.\n  ?problem      rdfs:label               ?problem_lbl.\n}"
            },
            "template_id": "T08",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2351",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the REL-RWMD k-NN model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"REL-RWMD k-NN\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2034",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Unsupervised S2S with attention model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Unsupervised S2S with attention\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2079",
            "query_type": "Factoid",
            "question": {
                "string": "Where can I find code references in papers that have used the SAN (ensemble model) model for benchmarking purposes?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"SAN (ensemble model)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0580",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Atari 2600 Crazy Climber dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Crazy Climber\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2423",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Wide ResNet-50 (edge-popup) model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Wide ResNet-50 (edge-popup)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1075",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the FB15k dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"FB15k\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "HQ0039",
            "query_type": "Non-factoid/Count/Negation",
            "question": {
                "string": "How many comparisons are there which don't have a class link?"
            },
            "paraphrased_question": [
                "What percentage of comparisons is without class link?"
            ],
            "query": {
                "sparql": "SELECT ?ratio\nWHERE {\n  {\n    SELECT (COUNT(?comparison) AS ?n_valid_comparisons)\n    WHERE {\n      ?comparison a orkgc:Comparison.\n    }\n  }\n  {\n    SELECT (COUNT(DISTINCT ?comparison_) AS ?n_comparisons_with_missing_class) {\n      ?comparison_ orkgp:compareContribution ?contribution.\n      FILTER(\n        NOT EXISTS {\n            ?comparison_ a orkgc:Comparison\n          }\n       )\n     }\n   }\n   BIND(\n     CONCAT(\n       ROUND(\n         xsd:double(?n_comparisons_with_missing_class) / xsd:double(?n_valid_comparisons + ?n_comparisons_with_missing_class) * 100\n       ),\n       \" %\"\n     ) AS ?ratio\n   )\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 3
        },
        {
            "id": "AQ1208",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the MPQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"MPQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1988",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the NovelTagging model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"NovelTagging\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2427",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the DY-MobileNetV2 \u00d70.5 model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DY-MobileNetV2 \u00d70.5\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0992",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the Yelp-14 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Yelp-14\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2360",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the ViT-L/16 (\\\"ImageNet-21k\\\") model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ViT-L/16 (\\\"ImageNet-21k\\\")\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0444",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the HMDB51 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"HMDB51\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0393",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the Amazon-5 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Amazon-5\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "HQ0064",
            "query_type": "Factoid",
            "question": {
                "string": "What is the total number of patients in the studies?"
            },
            "paraphrased_question": [
                "How many patients participate in the studies?"
            ],
            "query": {
                "sparql": "SELECT SUM(?number_of_patients)\nWHERE {\n  orkgr:R33008 orkgp:compareContribution ?contrib.\n  ?contrib orkgp:P15585 ?patients.\n  BIND(xsd:integer(?patients) AS ?number_of_patients)\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "chain",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 2
        },
        {
            "id": "AQ1414",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of bits/dimension metric on the CIFAR-10 benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"bits/dimension\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CIFAR-10\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1561",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the Yelp Binary classification dataset in terms of Error metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Error\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp Binary classification\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1098",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset CoLA?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CoLA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1522",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the enwik8 dataset in terms of Bit per Character (BPC) metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Bit per Character (BPC)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"enwik8\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0245",
            "query_type": "Factoid",
            "question": {
                "string": "What are the models that have been benchmarked on the Atari 2600 Atlantis dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Atlantis\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2248",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the ego-localization model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"ego-localization\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0395",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the TACRED dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"TACRED\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1478",
            "query_type": "Factoid",
            "question": {
                "string": "What is the best performing model benchmarking the CNN / Daily Mail dataset in terms of ROUGE-L metric?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"ROUGE-L\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"CNN / Daily Mail\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "HQ0006",
            "query_type": "Factoid",
            "question": {
                "string": "What kind of graph does ADANA use?"
            },
            "paraphrased_question": [
                "What kind of graph does the paper \"paper title\" use?"
            ],
            "query": {
                "sparql": "SELECT ?graph ?graph_label\nWHERE {\n  ?paper orkgp:P31 ?cont;\n         rdfs:label ?title.\n  FILTER(REGEX(?title, \"ADANA\"))\n  ?cont orkgp:P5008 ?graph. \n  ?graph rdfs:label ?graph_label.\n}"
            },
            "template_id": null,
            "auto_generated": false,
            "query_shape": "tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2160",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the AWD-LSTM-MoS model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM-MoS\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0515",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the GENIA - LAS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"GENIA - LAS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1969",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the CNN + LSTM + SVM model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"CNN + LSTM + SVM\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0555",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the CINIC-10 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CINIC-10\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0930",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the Atari 2600 Centipede dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Centipede\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1440",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of Top-1 Accuracy score when benchmarked on the Kinetics-600 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Top-1 Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Kinetics-600\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2017",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the DyGIE model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"DyGIE\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2040",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the PBSMT model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PBSMT\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1128",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark result (metric and value) over the dataset HMDB51 (finetuned)?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"HMDB51 (finetuned)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1528",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Test perplexity metric on the Penn Treebank (Word Level) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Test perplexity\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Penn Treebank (Word Level)\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0872",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the CoNLL 2003 (English) dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CoNLL 2003 (English)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0705",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the SemEval-2021 Task 11 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SemEval-2021 Task 11\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ2157",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the AWD-LSTM + continuous cache pointer model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"AWD-LSTM + continuous cache pointer\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ2223",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Fast Search model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Fast Search\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1925",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the PERCEIVER IO model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"PERCEIVER IO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1916",
            "query_type": "Factoid",
            "question": {
                "string": "List the code links in papers that use the Randmized Market segment Oblivious model in any benchmark?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Randmized Market segment Oblivious\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1192",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the  Jacquard dataset dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \" Jacquard dataset\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ1360",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the BUCC Russian-to-English dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"BUCC Russian-to-English\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0628",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the Atari 2600 Q*Bert dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Q*Bert\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0499",
            "query_type": "Factoid",
            "question": {
                "string": "Give me a list of research papers along with their titles and IDs, that have performed benchmarks on the enwiki8 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"enwiki8\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ1417",
            "query_type": "Factoid",
            "question": {
                "string": "What is the name of the top performing model in terms of BLEU score when benchmarked on the WMT2014 English-French dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"BLEU\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"WMT2014 English-French\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ2362",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the BiT-S model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"BiT-S\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0454",
            "query_type": "Factoid",
            "question": {
                "string": "What are the titles and IDs of research papers that include a benchmark for the BioASQ dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"BioASQ\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0603",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of research paper titles and IDs that have benchmarked models on the Atari 2600 Fishing Derby dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Fishing Derby\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0191",
            "query_type": "Factoid",
            "question": {
                "string": "Could you provide a list of models that have been tested on the Finger, spin (DMControl100k) benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Finger, spin (DMControl100k)\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ0036",
            "query_type": "Factoid",
            "question": {
                "string": "What models are being evaluated on the NLP-TDMS dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"NLP-TDMS\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  ?paper         orkgp:HAS_BENCHMARK      ?benchmark.\n  OPTIONAL {?paper      orkgp:HAS_MODEL          ?model.\n            ?model      rdfs:label               ?model_lbl.}\n}"
            },
            "template_id": "T01",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1624",
            "query_type": "Factoid",
            "question": {
                "string": "Which model has achieved the highest Accuracy (%) score on the  Jacquard dataset benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy (%)\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \" Jacquard dataset\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ0918",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the CL-SciSumm dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"CL-SciSumm\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1006",
            "query_type": "Factoid",
            "question": {
                "string": "Can you list the metrics used to evaluate models on the SVHN dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"SVHN\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1458",
            "query_type": "Factoid",
            "question": {
                "string": "Indicate the model that performed best in terms of Accuracy metric on the Natural Questions benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?model ?model_lbl\nWHERE {\n  ?metric     a       orkgc:Metric;\n              rdfs:label  ?metric_lbl.\n  FILTER (str(?metric_lbl) = \"Accuracy\")\n  {\n    SELECT ?model ?model_lbl\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Natural Questions\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value;\n                      orkgp:HAS_METRIC         ?metric.\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark;\n                    orkgp:HAS_MODEL          ?model.\n      ?model      rdfs:label               ?model_lbl.\n    }\n    ORDER BY DESC(?value)\n    LIMIT 1\n  }\n}"
            },
            "template_id": "T05",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 12
        },
        {
            "id": "AQ1323",
            "query_type": "non-factoid",
            "question": {
                "string": "Can you provide the highest benchmark result, including the metric and score, for the Yelp-5 dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"Yelp-5\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ0976",
            "query_type": "Factoid",
            "question": {
                "string": "List the metrics that are used to evaluate models on the Atari 2600 Robotank benchmark dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"Atari 2600 Robotank\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        },
        {
            "id": "AQ1892",
            "query_type": "Factoid",
            "question": {
                "string": "List the datasets benchmarked under the Skills Assessment research problem?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?dataset ?dataset_lbl\nWHERE {\n  ?problem       a                orkgc:Problem;\n                 rdfs:label       ?problem_lbl.  \n  FILTER (str(?problem_lbl) = \"Skills Assessment\")\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark;\n                  orkgp:P32                ?problem.\n}"
            },
            "template_id": "T06",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ0493",
            "query_type": "Factoid",
            "question": {
                "string": "List the title and ID of research papers that contain a benchmark over the LAMBADA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?paper ?paper_lbl\nWHERE {\n  ?dataset        a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"LAMBADA\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset.\n  ?cont          orkgp:HAS_BENCHMARK      ?benchmark.\n  ?paper         orkgp:P31                ?cont;\n                 rdfs:label               ?paper_lbl.\n}"
            },
            "template_id": "T02",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 5
        },
        {
            "id": "AQ2124",
            "query_type": "Factoid",
            "question": {
                "string": "Can you provide links to code used in papers that benchmark the Transformer (12 layers, 8k adaptive span) model?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Transformer (12 layers, 8k adaptive span)\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ1138",
            "query_type": "non-factoid",
            "question": {
                "string": "What is the top benchmark score and its metric on the PubMedQA dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl (MAX(?value) AS ?score)\nWHERE {\n  {\n    SELECT ?metric ?metric_lbl ?value\n    WHERE {\n      ?dataset       a                orkgc:Dataset;\n                      rdfs:label       ?dataset_lbl.\n      FILTER (str(?dataset_lbl) = \"PubMedQA\")\n      ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                      orkgp:HAS_EVALUATION    ?eval.\n      ?eval           orkgp:HAS_VALUE         ?value.\n      OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n               ?metric          rdfs:label               ?metric_lbl.}\n      ?cont         orkgp:HAS_BENCHMARK      ?benchmark.\n      OPTIONAL {?cont      orkgp:HAS_MODEL          ?model.\n                ?model      rdfs:label               ?model_lbl.}\n    }\n    ORDER BY DESC(?value)\n  }\n}\nGROUP BY ?metric ?metric_lbl"
            },
            "template_id": "T04",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 13
        },
        {
            "id": "AQ2251",
            "query_type": "Factoid",
            "question": {
                "string": "Provide a list of papers that have utilized the Depth DDPPO model and include the links to their code?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?code\nWHERE {\n  ?model    a            orkgc:Model;\n            rdfs:label    ?model_lbl.\n  FILTER (str(?model_lbl) = \"Depth DDPPO\")\n  ?benchmark      orkgp:HAS_DATASET        ?dataset.\n  ?cont           orkgp:HAS_BENCHMARK      ?benchmark.\n  ?cont           orkgp:HAS_MODEL          ?model;\n                  orkgp:HAS_SOURCE_CODE    ?code.\n}"
            },
            "template_id": "T07",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 4
        },
        {
            "id": "AQ0833",
            "query_type": "Factoid",
            "question": {
                "string": "What are the metrics of evaluation over the WNLI dataset?"
            },
            "paraphrased_question": [],
            "query": {
                "sparql": "SELECT DISTINCT ?metric ?metric_lbl\nWHERE {\n  ?dataset       a                orkgc:Dataset;\n                  rdfs:label       ?dataset_lbl.\n  FILTER (str(?dataset_lbl) = \"WNLI\")\n  ?benchmark      orkgp:HAS_DATASET       ?dataset;\n                  orkgp:HAS_EVALUATION    ?eval.\n  OPTIONAL {?eval           orkgp:HAS_METRIC         ?metric.\n           ?metric          rdfs:label               ?metric_lbl.}\n}"
            },
            "template_id": "T03",
            "auto_generated": true,
            "query_shape": "Tree",
            "query_class": "WHICH-WHAT",
            "number_of_patterns": 6
        }
    ]
}